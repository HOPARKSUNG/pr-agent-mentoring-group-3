# ✅ RAG(Retrieval-Augmented Generation)

## 📌 RAG 소개

외부 지식을 검색해서 답변에 반영하는 생성 모델

- LLM 내부 파라미터 외에, 외부의 신뢰할 수 있는 지식 베이스를 참조하도록 하는 프로세스
- 외부 문서를 검색하여 검색 결과를 참고하여 답변을 생성

<br/>

## 📌 RAG 필요성 및 등장 배경

기존 LLM은 다음의 문제점과 한계가 있었다.

- 지식 한계: 학습된 시점 이후 정보는 반영할 수 없음
    - 답변이 없으면 허위 정보를 제공
- 모델 크기 문제: 모든 지식을 기억하려면 엄청나게 거대해져야 함
- 비용 문제: 초거대 모델은 학습에 드는 비용이 비쌈

이러한 LLM의 한계를 해결하기 위한 한 가지 접근 방식으로 RAG가 등장했다.

<br/>

## 📌 RAG 구성 요소와 구조

`사용자 요청 → Retriever → 관련 문서 검색 → Generator → 답변 생성`

RAG는 Retriever(검색기)와 Generator(생성기), 두 가지 핵심 컴포넌트를 가진다.

- Retriever (검색기)
    - 유저 질문에 맞는 관련 문서/데이터를 빠르게 검색해 옴
    - ex) 벡터DB, BM25, FAISS, Milvus 등
- Generator (생성기)
    - 검색된 문서를 기반으로 자연어 답변을 생성함
    - ex) GPT, T5 같은 LLM

<br/>

## 📌 RAG 동작 원리

`[사용자 입력] → [관련 정보 검색] → [Context 강화] → [LLM에 전달] → [정확한 답변 생성]`

<img src="https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/jumpstart/jumpstart-fm-rag.jpg" width="500">

_이미지 출처: https://aws.amazon.com/ko/what-is/retrieval-augmented-generation/_

### 1. Prompt + Query 입력

- 사용자가 Prompt와 Query를 입력
    - ex) “삼성의 최신 스마트폰 출시 소식을 알려줘."
- Prompt는 지시(명령), Query는 실제 질문 내용

### 2. Query를 이용해 관련 정보 검색(Retriever 역할)

- 시스템은 Query를 이용해서 Knowledge Sources (문서, DB 등)에서 관련 정보를 검색

### 3. 관련 정보 받아오기(Retriever 역할)

- 검색 결과로 Enhanced Context를 구성할 수 있는 "관련 정보"를 받아옴
- LLM에 넘겨줄 때 같이 포함됨

### 4. Enhanced Context 조합

- 입력받은 Prompt + Query에 검색해서 얻은 Enhanced Context를 추가
    - 질문에 대해 추가 정보를 덧붙임
    - ex) 참고할 문서 일부를 같이 넘겨주기

### 5. LLM 호출 및 답변 생성(Generator 역할)

- 조합된 Prompt + Query + Enhanced Context를 LLM으로 보냄
- LLM은 이 풍부해진 정보를 기반으로 최종 텍스트 응답을 생성

<br/>

## 📌 RAG 장단점

### 장점

- 모델 크기를 줄이면서 최신 지식 반영 가능
- 최신 문서 기반으로 빠르게 업데이트 가능
- 특정 도메인 지식 커버에 유리
    - 특정 도메인을 위해 FM을 재교육하는 데 드는 비용도 절감
- 비용 효율적인 구현

### 단점

- Retriever 품질이 낮으면 답변도 부정확
- 검색된 문서가 많으면 Generator가 헷갈릴 수 있음
- Retriever+Generator 구성이라 시스템이 복잡해짐
- Context Window 한계
    - LLM이 한 번에 읽을 수 있는 문서 양 제한

<br/>

# ✅ MCP(Model Context Protocol)

## 📌 MCP 소개

LLM이 컨텍스트를 잘 이해하고 필요한 액션을 취할 수 있도록 도와주는 프로토콜

- 기존에 존재하는 LLM을 특정 목적이나 데이터에 맞게 맞춤화하는 일련의 절차
    - LLM이 다른 서비스들을 이용하기 쉽게 도와주는 소통 방식

<br/>

## 📌 MCP 필요성 및 등장 배경

기존 LLM은 다음의 문제점과 한계가 있었다.

- 범용적 LLM: 특정 도메인에는 정확성/용어가 부족할 수 있음
    - 자신들만의 데이터나 스타일로 응답하는 모델을 원함
- 애플리케이션과 데이터 소스 간의 상호작용이 비표준적: 데이터 접근 방법이 제각각
    - API 호출 방식, 데이터 포맷, 전송 규약이 일관되지 않아 통합이 어렵고 개발 비용이 증가
- 보안과 규제 문제: 민감한 정보를 다룰 때, 퍼블릭 모델을 그대로 쓰는 것은 위험함
    - 프라이빗 튜닝 필요
- 효율성과 비용 절감: 필요한 부분만 튜닝하면 전체를 새로 학습하는 것보다 훨씬 저렴하고 빠름

이러한 LLM의 한계를 해결하기 위한 한 가지 접근 방식으로 MCP가 등장했다.

<br/>

## 📌 MCP 구성 요소와 구조

`사용자 입력 → MCP Host → MCP Client → MCP Server → Resources`

MCP는 Host, Client, Server, 세 가지 핵심 컴포넌트(3-티어 아키텍처)를 가진다.

<img src="https://assets.apidog.com/blog-next/2025/03/Screenshot-2025-03-07-222608.png" width="500">

_이미지 출처: https://apidog.com/kr/blog/model-context-protocol-kr/_

### 1. Host(호스트)

MCP 전체 프로세스를 관리하고 조정하는 메인 컨트롤러 계층

- 여러 서버들과 통신하면서 각각 작업을 분배하거나 결과를 수집함
    - MCP 프로토콜을 사용하여 MCP 서버들과 통신
    - ex) Claude, IDE 등
- 사용자 인터페이스 제공, 사용자와 직접 상호작용함
    - 클라이언트와 서버 연결, 상태 모니터링, 튜닝 세션 시작 or 멈춤 등

### 2. Client(클라이언트)

MCP 호스트와 MCP 서버의 1:1 연결을 유지하는 프로토콜 통신 계층

- 호스트 내부에서 서버랑 직접 통신하는 레벨로, 프로토콜 구현체
- 상태 관리, 에러 핸들링, 메시지 직렬화/역직렬화 등 수행

### 3. Server(서버)

로컬 시소스나 외부 리소스에 직접 접근해 실제 튜닝/처리를 수행하는 계층

- MCP 요청을 받아서 모델 파인튜닝, 평가, 저장 등을 수행함
    - 다양한 서비스들을 표준화된 방식으로 활용할 수 있게 도와줌
- ex) MCP 서버 A → 로컬 리소스 A, MCP 서버 B → 외부 원격 리소스 C(Web API로 접근)

<br/>

## 📌 MCP 장단점

### 장점

- 특정 목적 및 도메인에 최적화 가능
- 컨텍스트 공유 표준화
- 비용 효율적
- 확장성

### 단점

- 초기 구축 복잡성
- AI 에이전트와 도구의 통합 문제

<br/>

# ✅ A2A(Agent-to-Agent)

## 📌 A2A 소개

AI 에이전트끼리 직접 대화하고 협력하여 문제를 해결하거나 목표를 달성하는 구조

- 사람이 개입하지 않고 AI Agent들끼리 자율적으로 상호작용하는 것

<br/>

## 📌 A2A 필요성 및 등장 배경

기존 LLM은 다음의 문제점과 한계가 있었다.

- 단일 모델 한계: 하나의 모델이 모든 문제를 잘 해결할 수는 없음
    - 전문성 부족, 처리 한계, 모델 정확성
- 복잡한 작업 분할 필요: 여러 단계로 나누어 해결할 때 각 단계마다 최적화된 Agent가 따로 필요함

이러한 LLM의 한계를 해결하기 위한 한 가지 접근 방식으로 A2A가 등장했다.

<br/>

## 📌 A2A 구성 요소 및 구조

`Client Agent → Agent Card 조회 → remote Agent 선택 -> 작업 객체 생성 및 요청 → remote Agent 작업 수행 → 결과 반환`

<img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_VkAG0Kd.original.png" width="500">

_이미지 출처: https://developers.googleblog.com/ko/a2a-a-new-era-of-agent-interoperability/_

### 1. Client Agent

작업(Task)을 시작하는 Agent

- 다른 Agent를 발견하고 적합한 Remote Agent를 선택해 작업을 요청
- Agent Card를 읽고 Remote Agent를 탐색 및 선택
    - Agent Card: 각 Agent의 기능, 기술, API 엔드포인트 등이 명시된 문서
- Task Object를 생성하여 요청 전송
    - Task Object: Client Agent가 Remote Agent에게 전달하는 구조화된 작업 요청
        - 상태 필드가 있어 작업의 진행 상황을 관리
        - ex) 요청됨(Requested) → 진행 중(In Progress) → 완료됨(Completed) → 실패(Failed)

### 2. Remote Agent

Client Agent로부터 작업을 수신하고 수행하는 Agent

- Task Object를 수신하고 실행
- 작업 결과를 Artifact 형태로 반환
    - Artifact: Remote Agent가 작업 수행 후 반환하는 결과물
        - 텍스트, JSON, 이미지, 비디오, 인터랙티브 폼 등 다양한 형태 가능
- 필요 시 중간 상태나 추가 협상 메시지를 Client Agent에 전달

<br/>

## 📌 A2A 장단점

### 장점

- 복잡한 문제를 효율적으로 분할 처리 가능
- 전문가처럼 역할을 나눠 더 높은 정확도를 낼 수 있음
- 새로운 Agent를 추가하여 시스템 유연하게 확장 가능

### 단점

- Agent 간 통신 비용 및 지연 증가
- 통신 오류나 오해로 인해 결과 품질 낮아질 수 있음
- 컨텍스트 공유 문제 발생 가능
