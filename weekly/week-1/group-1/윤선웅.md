# 💬 1주차 학습

이 문서는 [**GitHub Flow**](https://docs.github.com/en/get-started/using-github/github-flow) 및 [**대형 언어 모델(LLM)의 심층 분석: ChatGPT의 작동 방식 이해하기**](https://www.youtube.com/watch?v=6PTCwRRUHjE)에 대한 학습 내용을 정리한 자료입니다.  
LLM의 구조와 학습 방식, ChatGPT의 대화 능력 향상 과정을 체계적으로 분석하고 Git Flow 및 GitHub Flow의 협업 전략을 일부 정리하였습니다.

- 학습에 대한 자세한 정리는 [**Notion**](https://www.notion.so/ssunbear/OSSCA-PR-Agent-1da2c77b05c280eb9f2adc27ef2ed96b)에서 확인할 수 있고 해당 리드미는 학습정리를 핵심적으로 간단히 정리하였습니다.

---

# 💬 ChatGPT와 Git 협업 전략 이해하기

## 📌 LLM의 정의와 ChatGPT의 역할

- LLM은 인터넷상의 방대한 텍스트 데이터를 학습하여 인간 언어의 패턴을 익힌 거대 신경망 모델입니다.
- 주어진 **이전 단어들의 문맥을 바탕으로 다음에 올 단어를 예측**하도록 훈련되며, 번역, 요약, 질의응답 등 다양한 언어 작업에 활용됩니다.
- **ChatGPT**는 이러한 LLM 기술을 기반으로 만들어진 대화형 인공지능으로, OpenAI의 GPT 계열 모델에 **사용자의 지시에 따라 응답하도록 추가 훈련(미세조정)**된 사례입니다.
- 간단히 말해, ChatGPT는 **LLM에 대화 및 명령 수행 능력을 덧붙인 것**으로, **사용자와 대화하고 유용한 정보를 제공하는 AI 어시스턴트** 역할을 수행합니다.

---

### 🧭 Base Model vs. Instruction Tuning

- **Base Model**: 방대한 텍스트 코퍼스로 학습된 순수 언어 모델로, 다음 토큰 예측만 가능
- **Instruction-Tuned Model**: 사용자의 질문이나 명령에 유용하게 답할 수 있도록 추가 훈련된 모델

→ `Base`는 언어 패턴 학습, `Instruction-tuned`는 **사용자 지시 이해와 반응** 가능

---

## 📚 LLM 사전 훈련 (Pretraining) 과정

### 🔍 데이터 수집 및 정제
- Common Crawl 등에서 웹 데이터를 수집하고 정제

### 🔤 토큰화
- BPE 방식으로 텍스트를 토큰 단위로 분할  
  → [Byte Pair Encoding 설명](https://wikidocs.net/22592)

### 🧠 Transformer 학습
- Self-Attention으로 문맥 관계 학습

### 🎯 학습 목표
- Cross-Entropy Loss로 오차 최소화 + 역전파로 최적화

---

## 🧾 LLM의 추론 단계 (Inference)

1. `<BOS>` 시작 토큰 입력
2. 다음 토큰 예측 (`Greedy`, `Top-K`, `Temperature`)
3. 토큰 반복 생성
4. `<EOS>` 출력 or 최대 길이 도달 시 종료

> 생성 방식에 따라 **출력 다양성/일관성** 조절 가능

---

## 🤖 ChatGPT의 후속 학습 (Post-training)

### 🗣️ Supervised Fine-Tuning (SFT)
- 대화형 데이터셋 기반 지도 학습

### 🧠 RLHF (Reinforcement Learning from Human Feedback)
- 사람이 선호하는 답변을 기준으로 보상 모델 훈련  
- PPO 등의 알고리즘으로 LLM 파인튜닝

---

# 🌿 Git Branch 전략 정리

## Git Flow

> Local 중심의 브랜치 전략

### Branch 종류

- `main`: 배포용 브랜치, **직접 커밋 금지**
- `develop`: 기능 통합 및 다음 배포 준비
- `feature`: 기능 단위 작업 브랜치 (`feat/`, `fix/`, `refactor/`, `docs/` 등)
- `release`: 배포 준비용 브랜치, QA 및 버그 픽스 수행
- `hotfix`: 배포 이후 긴급 버그 수정용 브랜치

---

## GitHub Flow

> Remote 중심, 빠른 배포에 유리  
> 브랜치: `main` + `feature`

- `main`: 배포 기준, 모든 기능은 PR을 통해 merge
- `feature`: 작업용 브랜치, 이슈 번호 기반 네이밍 권장

> ✅ `main` merge 전 PR 리뷰는 필수!

---

# ✅ Commit Convention

## 🗂️ Commit Message 구조

### Type 예시
- `feat`: 기능 추가
- `fix`: 버그 수정
- `refactor`: 코드 리팩토링
- `docs`: 문서 변경
- `test`: 테스트 코드
- `chore`: 기타 잡무

---

## 🧼 Pre-commit Hook

- 코드 포맷팅 (black, prettier 등)
- 정적 분석 (flake8, pylint)
- 테스트 자동 실행 (pytest, jest 등)
- 의존성 충돌/누락 체크

> → 일관된 코드 품질 유지에 핵심

---

# 🧵 Issue와 Pull Request 관리

## 🪡 Issue

- 개발 단위 명세
- `feature/#123-login-api` 와 같이 **이슈 번호 기반 브랜치 생성 권장**

## 🔃 Pull Request (PR)

- **PR이란?**  
  → 로컬 작업을 원격 저장소에 merge 요청하는 절차

- **작성 시 포함 항목**
  - 작업 목적 및 관련 이슈 번호 (e.g., `Fixes #123`)
  - 변경 내용 요약
  - 테스트 내역 및 기타 확인 사항

- **PR 리뷰 체크포인트**
  - 코드 스타일 준수
  - 중복/불필요 로직 여부
  - 예외처리, 보안 고려 여부


---

## 📎 참고

- Git Flow 전략: [Atlassian Git Flow Guide](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow)
- GitHub Flow 전략: [GitHub Docs](https://docs.github.com/en/get-started/quickstart/github-flow)
- Byte Pair Encoding: [BPE 설명](https://wikidocs.net/22592)
- 영상 참고: [LLM의 작동 원리 - ChatGPT 분석](https://www.youtube.com/watch?v=6PTCwRRUHjE)

---
