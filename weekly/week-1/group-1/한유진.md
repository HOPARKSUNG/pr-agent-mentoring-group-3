# 1 주차 학습 주제

- Git 활용(GitHub Flow 중심)
- `사전 학습(LLM, Gemini API 사용법) 주제 학습`
- Pull Request 작성 및 리뷰 방법

이중 가장 취약한 LLM 에 집중하여 알아보고자 합니다.

# LLM (Large Language Model)

거대 언어모델

- 대규모 데이터 세트에서 훈련된 인공지능 언어 모델로, `자연어(NLP)`를 이해하고 생성할 수 있는 모델을 의미
    - NLP (**Natural language processing)**
        - 자연어 처리는 컴퓨터와 사람들이 인간의 언어를 사용하여 상호 작용할 수 있는 방법에 초점을 맞춘 인공지능 형태.
- 주로 딥러닝 기술을 사용하여 구축되며, 수십억 개의 파라미터를 포함 (GPT3 같은 경우 1750억개의 파라미터)
- 모델들은 문장 완성, 번역, 요약 등 다양한 자연어 처리 작업에 활용

## LLM을 만들기 위해 필요한 것

1. 대규모 텍스트 데이터
2. 엄청난 연산량의 컴퓨팅 소스 (GPU)
    1. nvidia 같은 회사가 기하급수적으로 수요가 많아짐

## LLM 학습 기본 원리

- 언어 모델 (Language Model)은 다음에 올 단어가 무엇인지 예측함
예) OO 위에 OOO이가 걸어다닌다
- 주어진 텍스트 기반으로 다음에 어떤 텍스트가 올지 적절하게 예측하는 것
예) Google, 네이버의 자동검색기능

## Foundation Model

범용성이 높고 다양한 응용 분야에서 사용될 수 있는 대규모 머신 러닝 모델

### 특징)
- 범용성
    - 하나의 모델이 다양한 작업에 적용됨
    - 텍스트 생성, 번역, 요약, 질문 응답
- 전이학습 (Transfer Learning) 기능
    - 파운데이션 모델은 일반적으로 특정 작업에 특화된 모델보다 더 많은 데이터로 훈련됨. 따라서 이러한 모델을 기반으로 작은 양의 추가 데이터로 특정 작업에 빠르게 적응할 수 있음
- 데이터 효율성
    - 막대한 양의 데이터에서 훈련되기 때문에, 일반적으로 더 작은 양의 데이터로도 높은 성능을 나타낼 수 있음
- 응용 분야의 다양성
    - 이러한 모델들 자연어 처리뿐만 아니라, 이미지 인식, 음성 인식, 추천 시스템 등 다양한 분야에서 화룡됨
- 윤리적, 사회적 이슈
    - 범용성으로 인해, 편향성, 해석 가능성, 데이터 프라이버시 등 여러 윤리적 사회적 문제를 수반할 수 있음

## Foundation Model

- 기업별로 대표적인 파운데이션 모델들을 제공함
- OpenAI - GPT (1,2,3,3.5,4)
- Meta (Facebook) - Llama1, Llama2
- Google - PaLM

### RLHF (Reinforcement Learning from Human Feedback)

- 기초 Foundation Model 들을 제품화하기 위해서 Reinforcement Learning from Human Feedback 기법이 활용된다
    - LLM모델에 대해, 사람이 평가를 하여 사람이 선호하는 Response를 내보내끔 걸러줌
    - Internet에 논란이 되는 욕설 발언등을 학습과정에서 필터링을 함

## LLM의 잠재적 위험성

- 편향과 할루시네이션
- 편향
    - 데이터로부터의 편향 : LLM은 대규모 데이터셋에서 훈련되기 때문에, 그 데이터셋에 내재된 사회적, 문화적 편향을 학습할 수 있다.
    - 확인 편향 : 모델은 때로 사용자의 의견이나 선입견을 더 깊게 뿌리 내릴 수 있다. 예를 들어, 모델에게 특정 주제에 대한 의견을 물으면, 사용자가 원하는 대답을 하려고 하는 경향이 있을 수 있다.
    - 편향의 증폭 : 모델이 특정 집단이나 개념에 대해 더 극단적인 또는 편향된 정보를 생성하거나 전달하는 경우도 있다.
- 할루시네이션
    - 잘못된 지식을 참된 지식인 것 처럼 response함
    - 정보의 부정확성 : LLM 은 때로는 현실과 다른, 부정확한 정보를 생성할 수 있다. 이는 특히 통계적 특성에 기반한 언어 모델의 한계 때문
    - 추론 오류: 모델이 문맥을 정확히 이해하지 못하여 잘못된 추론을 하는 경우가 있음
    - 데이터 왜곡: 모델이 훈련 데이터에 없던 정보를 생성할 수 있음.

[참고자료]

[**CodeBuddy 와 함께하는 AI 코드리뷰**](https://if.kakao.com/session/35)

[**대형 언어 모델(LLM)의 심층 분석: ChatGPT의 작동 방식 이해하기**](https://www.youtube.com/watch?v=6PTCwRRUHjE)

[ChatGPT의 원리 - 대규모 언어 모델 (LLM) 개념 정리](https://www.youtube.com/watch?v=-vnxFKHmKjc)

https://www.elastic.co/kr/what-is/natural-language-processing