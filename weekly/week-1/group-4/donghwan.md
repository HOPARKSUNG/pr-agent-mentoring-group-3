## 학습

[대형 언어 모델(LLM)의 심층 분석 : ChatGPT의 작동 방식 이해하기](https://www.youtube.com/watch?v=6PTCwRRUHjE) 영상 시청 및 학습

- ai를 이용한 유튜브 영상 요약 + 영상 시청으로 학습 중
- 현재 시청한 부분
  - 모델이 생각하기 위해서는 토큰이 필요하며 한번에 답을 내기보다는 중간과정이 있는 계산과정을 유도해 컨텍스트로 사용하면 좋다는 내용까지 시청
- 영상 요약본과 개인 메모를 적은 후 claude를 이용해 한번 더 가독성 있게 정리

## 요약

### ⚙️ LLM 구축 과정: 사전 훈련 단계

사전 훈련은 대규모 언어 모델(LLM) 개발의 가장 기초적인 단계입니다. 이 과정의 핵심은 인터넷에서 방대한 양의 텍스트 데이터를 수집하고 처리하는 것입니다.

#### 데이터 수집 절차

1. 데이터 원천: Common Crawl이 주요 출발점이 됩니다. 이 단체는 2007년부터 인터넷을 체계적으로 크롤링하여 웹의 방대한 콘텐츠를 아카이브해왔습니다.
2. 데이터 규모: 프로덕션 수준의 LLM을 훈련시키기 위해서는 약 44테라바이트에 달하는 디스크 공간이 필요할 정도의 방대한 양의 데이터가 요구됩니다.
3. 데이터 품질 관리: 허깅 페이스의 FineWeb 데이터셋과 같은 정제된 데이터셋은 다음과 같은 과정을 거쳐 만들어집니다:
   1. URL 필터링 (유해 사이트, 스팸, 저품질 콘텐츠 제거)
   2. HTML에서 텍스트 추출
   3. 언어별 필터링
   4. 중복 콘텐츠 제거
   5. PII(개인식별정보) 제거

#### 📝 텍스트 표현: 토큰화

신경망에 텍스트를 입력하기 위해서는 먼저 컴퓨터가 이해할 수 있는 형태로 변환해야 합니다. 신경망은 기본적으로 유한한 기호 집합으로 구성된 1차원 시퀀스를 처리합니다. 이러한 변환 과정을 '토큰화'라고 합니다.

#### 토큰화 과정

1. 텍스트 인코딩: 먼저 텍스트를 UTF-8과 같은 인코딩 방식을 사용하여 이진 데이터(0과 1)로 변환합니다.
2. 바이트 표현: 이진 데이터를 8비트 단위(바이트)로 그룹화하여 0-255 사이의 값으로 표현합니다. 이를 통해 256가지 기본 기호를 표현할 수 있습니다.
3. [바이트 쌍 인코딩](https://wikidocs.net/22592)(BPE): 텍스트에서 자주 함께 등장하는 연속된 바이트나 기호들을 분석하여 하나의 새로운 토큰으로 병합합니다. 이 과정을 반복하여 효율적인 어휘 사전을 구축합니다.
4. 사전 구축: 이렇게 생성된 토큰들을 모아 모델의 어휘 사전을 구성합니다.

#### 토큰화의 중요성

토큰화 과정에서는 어휘 사전의 크기(토큰 수)와 시퀀스 길이 사이의 균형이 중요합니다. 사전이 너무 작으면 각 토큰이 담는 정보량이 적어 시퀀스가 길어지고 너무 크면 메모리 사용량이 증가하고 학습이 어려워집니다.

예를 들어 GPT-4는 약 100,277개의 토큰을 포함하는 어휘 사전을 사용합니다. 이 토큰들은 단일 문자부터 자주 사용되는 단어, 단어 조각까지 다양합니다.

텍스트가 실제로 어떻게 토큰화되는지 확인하려면 [Tick Tokenizer](https://tiktokenizer.vercel.app/)와 같은 도구를 활용할 수 있습니다. 이를 통해 특정 텍스트가 GPT-4와 같은 모델에 어떻게 입력되는지 시각화할 수 있습니다.

### 🧠 신경망 훈련: 통계적 관계 모델링

신경망 훈련 단계에서는 토큰들이 시퀀스에서 서로 어떻게 따라가는지에 대한 통계적 관계를 모델링합니다. 데이터에서 토큰 창을 만들고 시퀀스에서 다음에 오는 토큰을 예측합니다. 신경망은 다음에 올 토큰의 확률을 출력하며 훈련 초기에는 무작위로 초기화됩니다.

신경망은 다음에 오는 올바른 토큰에 더 높은 확률을 부여하기 위해 업데이트됩니다. 이 과정은 전체 데이터 세트의 모든 토큰에 대해 동시에 발생하며 이것이 신경망을 훈련하는 과정입니다. 훈련 세트에서 실제로 발생하는 통계와 예측이 일치하도록 업데이트합니다.

신경망 내부에는 입력 토큰이 있으며 이는 파라미터 또는 가중치와 함께 거대한 수학적 표현식으로 혼합됩니다. 처음에는 이러한 파라미터가 완전히 무작위로 설정되지만 반복적인 업데이트를 통해 훈련 세트에서 보이는 패턴과 일관성을 갖게 됩니다.

### ✨ 추론 단계: 새로운 데이터 생성

추론 단계에서는 모델에서 새로운 데이터를 생성합니다. 원하는 시작점과 같은 접두사인 일부 토큰으로 시작하여 네트워크에 입력하면 네트워크가 확률을 제공합니다. 이 확률 분포에 따라 토큰을 샘플링하여 모델에서 생성합니다.

각 단계마다 동전을 던지듯 샘플링하며 운이 좋으면 훈련 세트에서 텍스트의 작은 부분을 재현할 수 있지만, 훈련 데이터의 어떤 문서에도 그대로 포함되지 않은 토큰을 얻을 수도 있습니다. 훈련에서 본 데이터의 리믹스 같은 것을 얻게 될 것입니다.

가장 일반적인 시나리오에서 인터넷을 다운로드하고 토큰화하는 것은 전처리 단계입니다. 네트워크 훈련을 수행하고 만족스러운 특정 매개변수 집합을 얻으면 모델을 가져와서 추론을 수행하고 실제로 모델에서 데이터를 생성할 수 있습니다.

Chat GPT 사이트에서 모델과 대화할 때 해당 모델은 추론만 수행합니다.

### 💰 연산에는 GPU가 많이 필요하다

신경망 학습에는 엄청난 양의 계산이 필요하며 GPU는 이러한 복잡한 연산을 처리하는 데 최적화되어 있습니다. GPU가 AI 발전에 핵심적인 역할을 하는 이유는 다음과 같습니다.

#### GPU의 장점

1. 병렬 처리 능력: GPU는 수천 개의 코어를 가지고 있어 동시에 수많은 계산을 처리할 수 있습니다. 이는 행렬 연산이 대부분인 신경망 학습에 이상적입니다.
2. 확장성: 여러 GPU를 연결하여 분산 학습을 수행할 수 있으며, 이들은 서로 효율적으로 협업하여 대규모 모델 훈련이 가능합니다.
3. 가속화된 학습: CPU만 사용할 때보다 수십에서 수백 배 빠른 학습 속도를 제공합니다.

일론 머스크와 같은 기업가들이 단일 데이터 센터에 10만 개의 GPU를 확보하려는 이유는 명확합니다. GPU가 많을수록 데이터 세트를 더 빠르게 처리하고 더 큰 네트워크를 구축하고 훈련할 수 있습니다.

### 📚 기본 모델: 토큰 시뮬레이터

기본 모델은 인터넷 텍스트 토큰 시뮬레이터입니다. 그 자체로는 아직 유용하지 않지만, 시퀀스에서 다음 토큰을 예측하는 작업에서 모델이 세상에 대해 많은 것을 배웠고 그 모든 지식을 네트워크 파라미터에 저장했기 때문에 여전히 매우 유용합니다.

기본 모델은 인터넷의 일종의 압축이라고 생각할 수 있습니다. 4,050억 개의 파라미터는 일종의 zip 파일과 같지만, 무손실 압축이 아니라 손실 압축입니다. 인터넷의 게슈탈트가 남아 그것으로부터 생성할 수 있는 것과 같습니다.

기본 모델에 적절한 프롬프트를 제공하여 이 지식의 일부를 이끌어낼 수 있습니다. 예를 들어, 파리에서 볼 수 있는 최고의 랜드마크 상위 10개 목록과 같은 프롬프트를 사용할 수 있습니다. 모델은 인터넷 문서의 일부를 회상하여 결과를 내놓습니다.

### 👩‍🏫 후속 훈련: LLM을 비서로 전환

후속 훈련 단계에서는 기본 모델, 즉 인터넷 문서 시뮬레이터를 가져다가 후속 훈련에 넘깁니다. 이 단계는 계산적으로 훨씬 저렴하며, 이 LLM 모델을 비서로 전환합니다. 모델이 인터넷 문서를 샘플링하지 않고 질문에 대한 답변을 제공하도록 하려면 어떻게 해야 할까요?

우리는 대화에 대해 생각하기 시작해야 합니다. 대화는 다중 턴이 될 수 있으며, 가장 간단한 경우 인간과 비서 간의 대화입니다. 비서가 어떻게 응답해야 하는지 생각하고 이러한 대화에서 비서와 그 행동을 프로그래밍해야 합니다.

신경망이기 때문에 코드에서 명시적으로 프로그래밍하지 않고, 대화 데이터 세트에 대한 신경망 학습을 통해 어시스턴트를 암묵적으로 프로그래밍하게 됩니다. 사람 라벨러에게 대화 맥락을 제공하고, 이 상황에서 이상적인 어시스턴트 응답을 제공하도록 요청합니다.

기본 모델을 가져와서 인터넷 문서 데이터 세트를 버리고 새로운 데이터 세트로 대체합니다. 대화 데이터 세트에 대해 모델을 계속 훈련하면 모델이 매우 빠르게 조정되고 어시스턴트가 인간 쿼리에 응답하는 방식에 대한 통계를 학습합니다.

### 💬 대화의 토큰화

대화는 토큰 시퀀스로 변환되어야 합니다. 대화와 같은 데이터 구조가 토큰으로 인코딩 및 디코딩되는 방식에 대한 몇 가지 규칙이 필요합니다. 모든 LLM은 약간씩 다른 형식이나 프로토콜을 가지고 있습니다.

GPT-4o는 `I Amore start`라는 특수 토큰을 추가하여 사용자-어시스턴트 간의 차례를 구분합니다. 이러한 특수 토큰은 텍스트와 함께 삽입되어 모델이 차례의 시작과 끝을 학습하도록 합니다.

추론 시에는 컨텍스트를 구성하고 모델에서 샘플링을 시작합니다. 모델로 이동하여 시퀀스에 적합한 토큰을 묻고, LM이 역할을 하여 응답을 생성합니다. 이러한 종류의 대화가 데이터 세트에 있는 경우 이와 비슷한 느낌을 줄 것입니다.

### 🤝 인간 라벨러와 라벨링 지침

OpenAI와 같은 회사는 Upwork나 Scale AI를 통해 고용한 계약직 직원들이 대화를 구성하도록 합니다. 이들은 프롬프트를 만들고 이상적인 어시스턴트 응답을 완성하도록 요청받습니다.

OpenAI와 같이 언어 모델을 개발하는 회사는 인간이 이상적인 응답을 만드는 방법에 대한 라벨링 지침을 작성합니다. 라벨링 지침은 일반적으로 짧지 않고 수백 페이지에 달하며, 사람들은 전문적으로 연구해야 합니다.

InstructGPT 데이터 세트는 OpenAI에서 실제로 공개하지 않았지만, 우리는 이러한 설정을 따르고 자체 데이터를 수집하려는 오픈 소스 복제본을 가지고 있습니다. 예를 들어, 과거의 Open Assistant의 노력이 있습니다.

모델이 테스트 시간에 접하게 될 수 있는 모든 가능한 질문을 완전히 다룰 수는 없지만, 이러한 예제 데이터 세트가 몇 개 있다면 훈련 중에 모델은 유용하고 진실하며 무해한 어시스턴트라는 페르소나를 갖기 시작할 것입니다. 시스템은 통계적으로 이 회사가 만드는 라벨링 지침에 반영된 유용하고, 진실하며, 무해한 어시스턴트라는 페르소나를 채택합니다.

최근에는 인간이 더 이상 혼자서 모든 힘든 일을 하는 경우는 흔하지 않습니다. 기존 LLM을 사용하여 기본적으로 답변을 제시한 다음 편집하거나 하는 경우가 훨씬 더 많습니다. LLM은 기본적으로 이러한 대규모 대화 데이터 세트를 만드는 데 광범위하게 사용됩니다.

Chat GPT에 가서 질문을 하고 엔터를 누르면, 나오는 결과는 훈련 세트에서 일어나는 일과 통계적으로 일치하는 경향이 있습니다. 따라서 Chat GPT에서 실제로 무엇과 대화하고 있는 걸까요? 그것은 어떤 마법 같은 AI에서 나오는 것이 아니라, 대략적으로 말하면 회사에서 작성한 라벨링 지침에서 비롯된 인간 라벨러를 통계적으로 모방하는 것에서 나옵니다.

평균적인 라벨러와 대화하고 있는 것입니다. 이 평균적인 라벨러는 꽤 숙련되어 있을 가능성이 높지만, 이러한 데이터 세트 구성에 고용될 만한 사람의 순간적인 시뮬레이션과 대화하고 있는 것입니다.

### 🤔 LLM 심리학: 환각과 완화

LLM이 내용을 지어내거나 정보를 완전히 날조하는 경우를 환각이라고 합니다. 이 문제는 수년 전 초기 모델에 널리 존재했던 문제였고, 몇 가지 완화 방법 덕분에 조금 나아졌다고 생각합니다.

테스트 시간에 '누구는 누구인가'라고 물어볼 때, 어시스턴트가 '모르겠어요'라고 말하지 않는다는 것이 문제입니다. 모델은 통계적으로 훈련 세트를 모방하기 때문에, 답변 스타일을 취하고 최선을 다할 것입니다. 모델들은 인터넷에 접속할 수 없기 때문에, 그저 시퀀스에서 다음 토큰을 샘플링하려고 노력하고 기본적으로 내용을 지어낼 것입니다.

환각 문제를 해결하기 위해서는 데이터 세트에 모델이 특정 사실에 대해 알지 못한다는 올바른 답변이 있는 예가 필요합니다. 모델이 무엇을 알고 무엇을 모르는지, 지식의 경계를 파악하기 위해 모델을 심문하는 절차가 필요합니다. 그런 다음 모델이 모르는 것에 대해 정답이 '모델이 모른다'인 예제를 훈련 세트에 추가합니다.

메타는 훈련 세트에서 임의의 문서를 가져와서 단락을 가져온 다음 LLM을 사용하여 해당 단락에 대한 질문을 구성합니다. 모델이 이 답변에 대해 알고 있을까요? 모델에서 답변을 가져와서 정답과 비교합니다. 모델이 모르면 모델이 이 질문을 모른다는 것을 알 수 있습니다.

환각 현상을 완화하기 위해 '모른다'라고 말하는 대신 LLM에게 사실을 말하고 질문에 답할 수 있는 기회를 제공하기 위해 두 번째 완화책을 도입할 수 있습니다. 모델이 기억이나 회상을 새로 고칠 수 있게 하는 것과 동등한 것이 필요하며, 모델에 도구를 도입하여 이를 수행할 수 있습니다.

언어 모델이 특수 토큰을 내보낼 수 있는 메커니즘을 만들 수 있습니다. 모델이 모르는 질문에 답하는 대신 모델은 이제 특수 토큰 검색 시작을 내보낼 수 있는 옵션이 있으며, 이는 OpenAI의 경우 bing.com 또는 Google 검색 등으로 이동하는 쿼리입니다. 웹 검색은 도구 중 하나일 뿐입니다.

모델이 검색 시점을 결정하고, 도구를 사용하는 방법은 환각 현상과 사실성을 완화하는 추가적인 방법입니다. 신경망 파라미터에 저장된 지식은 희미한 기억이며, 컨텍스트 창을 구성하는 토큰에 담긴 지식은 작업 기억입니다.

특정 내용을 기억하도록 하려면, 그냥 직접 제공하는 것이 항상 더 효과적입니다. 모델에서 직접 사용할 수 있기 때문입니다. '당신은 누구인가요? 누가 당신을 만들었나요?' 등과 같이 묻는 것은 실제로 의미가 없습니다.

### 🧠 모델은 생각하기 위해 토큰이 필요하다

언어 모델이 가진 능력과 한계는 토큰 기반 처리 방식에서 비롯됩니다. 모델은 인간처럼 글자 단위로 세상을 바라보지 않고 토큰이라는 작은 텍스트 덩어리 단위로 정보를 처리합니다.

### 모델의 약점

#### 문자 수준 작업의 취약성

"strawberry에 r은 몇 개인가?"와 같은 단순한 문자 수준 질문에도 오답을 제시하는 경우가 많습니다. 모델은 글자가 아닌 토큰 단위로 텍스트를 인식하기 때문에 개별 문자를 정확히 세는 능력이 제한적입니다.

#### 특정 비교 판단의 오류

"9.11이 9.9보다 크다"와 같은 주장을 할 때 성경 구절 표기 방식처럼 순서적으로 해석하는 등의 오류를 보입니다. 모델은 때로 숫자를 숫자 자체보다 텍스트 패턴으로 인식합니다.

#### 모델의 강점

##### 전문 지식 분야

모델은 올림피아드급 수학 문제나 박사급 생명과학, 물리, 화학 문제는 상당히 잘 풀어내는 경우가 많습니다. 이는 학습 데이터에 이러한 분야의 정보가 풍부하게 포함되어 있기 때문입니다.

##### 복사-붙여넣기 능력

모델은 제시된 정보를 그대로 반복하거나 재구성하는 작업에 능숙합니다. 이는 토큰 기반 예측의 특성과 잘 맞기 때문입니다.

##### 도구 사용 유도

Python과 같은 코드 실행 도구를 사용하도록 프롬프팅하면 훨씬 정확한, 특히 계산과 관련된 결과를 얻을 수 있습니다. 이는 모델이 직접 계산하는 대신 검증된 도구를 활용하기 때문입니다.

##### 단계적 사고 유도

언어 모델에게 바로 답을 요구하면 먼저 결론을 내리고 나서 그 결론을 지지하는 중간 과정을 역으로 구성하는 경향이 있습니다. 반면, 단계적 사고를 유도하여 중간 과정을 차례대로 생성하도록 하면 각 단계의 결과가 다음 판단의 컨텍스트로 활용되어 더 정확한 최종 결론에 도달합니다.

복잡한 문제는 중간 단계를 명시적으로 기록하도록 유도하여 더 정확한 결과를 얻을 수 있습니다.

#### 결론

언어 모델은 놀라운 능력을 갖추고 있지만, 여전히 한계가 분명합니다. 토큰 기반 처리 방식의 특성을 이해하고, 모델이 잘하는 영역과 약한 영역을 파악하여 적절히 활용하는 것이 중요합니다. 마법처럼 보이는 이 확률적 시스템은 맹목적인 신뢰보다는 비판적 검토와 함께 사용될 때 가장 유용합니다.

## 추후 학습에 도움될 링크

open ai에서 제공하는 프롬프팅 가이드 : https://academy.openai.com
구글에서 제공하는 프롬프팅 가이드: https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf?utm_source=ABLEARN&utm_campaign=503cfb68d8-EMAIL_CAMPAIGN_2023_03_14_09_47_COPY_01&utm_medium=email&utm_term=0_-52908238c9-%5BLIST_EMAIL_ID%5D
