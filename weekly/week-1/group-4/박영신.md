# 1주차 개인 과제

**학습 주제**
- Git 활용(GitHub Flow 중심)
- 사전 학습(LLM, Gemini API 사용법) 주제 학습
- Pull Request 작성 및 리뷰 방법

---

## Git 활용 - Github Flow 중심 + PR 작성

### 1. 협업 프로젝트에서의 Git 사용 흐름

- 협업에서는 _중앙 저장소(upstream)_ 와 _개인 저장소(origin)_, _로컬 저장소(local)_ 를 함께 사용

- **작업 흐름**
    1. 중앙 저장소를 `fork` 하여 개인 저장소를 만든다.
    2. 개인 저장소를 `clone` 하여 로컬에서 작업을 시작한다.
       1. 보통 중앙 저장소를 `upstream`, 개인 저장소를 `origin`이라 칭한다.
    3. 기능을 구현한 뒤 `add`, `commit`, `push` 순서로 개인 저장소(origin)에 업로드한다.
    4. GitHub에서 Pull Request(PR)를 생성하여 중앙 저장소(upstream에 병합을 요청한다.
    5. 리뷰가 승인되면, 중앙 저장소의 default branch에 머지한다.

- **주의 사항**
    - PR을 보내기 전, `pull`을 통해 중앙 저장소의 최신 변경 사항을 반드시 반영한다.
    - 이는 다른 팀원이 중앙 저장소를 갱신했을 가능성이 있기 때문이다.

- **핵심 요약**
    - 로컬 → origin → upstream 으로 흐름을 관리한다.
    - 중앙 저장소와의 충돌을 방지하기 위해 항상 **push 전 pull**을 습관화해야 한다 !
- 아래 사진은 이를 도식화한 것이다.

| <img width="400" src="https://github.com/user-attachments/assets/9172109e-2fb4-4fa6-a7af-bf2c62c2e0d2" /> | <img width="400" src="https://github.com/user-attachments/assets/a3bd596f-2bb8-4a62-8f74-988389fb5251" /> |

### 2. Pull Request 작성 및 리뷰 방법
개발을 진행하다보면 급해서 팀별로 설정해놓은 PR 방식을 따르기가 쉽지 않아진다. 
하지만, 원활한 협업을 위해서 아래와 같이 진행하면 매우 이상적이다.

**1. 분명한 기능 단위로 PR 나누기**
- 한 PR에 여러 작업이 섞이면 리뷰 효율이 급격히 떨어진다.
- 그래서 하나의 기능 또는 처리 흐름에 해당하는 범위만 담는 것이 이상적이다.

**2. 코드 제출 전 점검**
- 직접 코드를 읽어보며 이상한 부분, 테스트용 코드, 불필요한 주석 등을 제거한다.
- 특히, Github에 올라가면 안 되는 정보가 올라가지 않도록 주의한다.

**3. 변경 목적에 대한 충분한 설명**
- 어떤 문제를 해결했는지, 왜 이런 방식으로 구현했는지를 제목과 본문에 작성한다.
- 변경 내용 자체보다 ‘이유’와 ‘배경’을 명확히 하는 것이 핵심이다.

**4. 적극적인 리뷰 프로세스 참여**
- 담당 리뷰어를 태그하거나 별도 알림으로 요청하는 것이 좋다.
- 리뷰에 남긴 의견엔 확인 표시 또는 답변을 남긴다.
- 수정할 부분은 빠르게 반영해 커뮤니케이션 흐름 유지한다.

**5. 리뷰 자동화를 위한 도구 연동**
- PR 생성 시 자동으로 테스트 실행, 코드 스타일 검사 등을 수행하도록 설정한다.
- 라벨, 템플릿 등 반복 작업은 자동화해 효율적인 협업 문화 형성한다.

---

## LLM, Gemini API 사용법 주제 학습
해당 내용에 대한 공부는 아래의 링크를 참고하였다.<br>
- https://www.youtube.com/watch?v=6PTCwRRUHjE<br>
- https://aistudio.google.com/welcome

### 1. LLM(Large Language Model) 개요
- LLM 정의: 대규모 텍스트 데이터를 기반으로 학습하여 자연어를 이해하고 생성할 수 있는 딥러닝 모델
- 대표 LLM: GPT(OpenAI), Gemini(Google), Claude(Anthropic), LLaMA(Meta) 등 
- 핵심 구조: Transformer 기반 
  - 문맥 이해를 위한 Self-Attention 구조 채택 
  - 병렬 처리가 가능하여 대규모 데이터 학습에 유리함

### 2. LLM 학습 및 동작 방식

#### 사전 학습 (Pretraining)
- 웹, 뉴스, 위키 등의 범용 텍스트로 Self-supervised 방식 학습 
- 일반적으로 다음 토큰 예측 방식 사용 
- 모델은 언어의 구조와 문맥, 패턴을 통계적으로 학습

#### 미세 조정 (Finetuning)
- 특정 태스크(예: 요약, QA, 번역 등)에 특화되도록 학습 
- 정답(label)이 포함된 데이터셋을 이용해 성능 보정

#### 추론 (Inference)
- 입력된 프롬프트에 기반해 다음 토큰을 하나씩 예측하며 응답 생성
- 디코딩 전략:
  - Greedy, Top-k, Top-p, Temperature 조절 등 사용

### 3. Prompt Engineering
- LLM이 원하는 방식으로 응답하도록 프롬프트를 설계하는 기술
- 별도 학습 없이 다양한 작업 수행 가능

#### 주요 기법
- Zero-shot prompting: 예시 없이 직접 지시
- Few-shot prompting: 몇 개의 예시를 함께 제공
- Chain-of-Thought(CoT): 단계적 사고 유도
- Instruction prompting: 역할과 출력 양식 지정

#### Best Practice
- 역할 부여: “너는 전문가야”
- 출력 형식 지시: “표로 작성해줘” 
- 제약 조건 설정: “3문장 이내, 한글로 답변”

### 4. Gemini API 개요
- Google이 제공하는 멀티모달 LLM 기반 API
- 텍스트뿐 아니라 이미지, 코드 등 다양한 입력을 지원

#### 사용 방법
1.	Google Cloud Console에서 API 키 발급
2.	Python 또는 REST 방식으로 API 호출
3.	JSON 형식으로 프롬프트 전달 및 응답 수신

#### 주요 특징
- 높은 응답 품질과 최신 정보 기반
- Google 제품군과의 연동 편의성
- 다양한 디코딩 옵션 제공

### 5. 활용 예시
- 텍스트 요약: 긴 기사나 리포트를 짧은 문장으로 요약 
- 질의응답 시스템: 사용자의 질문에 대해 정확한 답변 생성 
- 콘텐츠 생성: 이메일, 광고 문구, 소셜 포스트 자동 생성 
- 코드 설명/리뷰: 소스 코드에 대한 자동 설명 또는 리뷰 작성

### 6. 실습 내용 및 적용 사례

이번 학습 과정에서 Google Cloud Console을 통해 Gemini API 키를 발급받고, Python을 활용하여 실제 API 호출을 진행해보았다. REST 방식과의 차이점도 확인했으며, JSON 형식으로 프롬프트를 구성하여 응답을 받아보는 과정에서 다양한 디코딩 전략의 영향을 실감할 수 있었다.

예를 들어, 같은 질문에 대해 top-k, top-p, temperature 값을 달리하여 응답의 다양성과 창의성이 어떻게 바뀌는지를 테스트해보았으며, 단순 지식 질문부터 감성 분석까지 프롬프트 유형별로 응답 품질을 비교하였다.

또한, 역할 부여와 출력 형식 지정 등의 프롬프트 엔지니어링 전략이 실제 응답에 어떤 차이를 주는지 실습하며, Gemini API의 프롬프트 최적화 가능성을 경험할 수 있었다.

**실습 코드 예시**
```python
import google.generativeai as genai

# API 키 설정
genai.configure(api_key="YOUR_API_KEY")

# 모델 선택
model = genai.GenerativeModel("gemini-pro")

# 프롬프트 입력
response = model.generate_content("한국의 수도는 어디인가요?")

# 응답 출력
print(response.text)

다양한 디코딩 전략 테스트 예시

response = model.generate_content(
"이 문장을 영어로 번역해줘: 나는 학교에 간다",
generation_config={
"temperature": 0.9,
"top_k": 5,
"top_p": 0.8
}
)
print(response.text)
```
