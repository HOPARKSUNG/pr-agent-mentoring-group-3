# 1주차 과제 - 개인 학습 내용 정리

---

## 1. Git과 Pull Request

### 1.1. Git, Git Flow, GitHub Flow

- **Git** : 분산 버전 관리 시스템. 코드 변경 이력을 효율적으로 관리 가능해 협업에 효과적.

- **Git Flow** : 전통적인 브랜치 전략. 배포 방식이 릴리즈 주기 중심. (->안정적인 릴리즈 프로세스, 복잡한 프로젝트에 적합)
  - 브랜치 구성 예:
    - `main`: 배포 가능한 최종 버전
    - `develop`: 다음 릴리즈를 위한 개발 브랜치
    - `feature/`: 기능 단위 개발 브랜치 (ex. `feature/login`)
    - `release/`: 릴리즈 준비 브랜치
    - `hotfix/`: 운영 중 긴급 수정
  
- **GitHub Flow** : GitHub에서 주로 사용하는 간결한 브랜치 전략. PR 머지 후 바로 배포 가능하므로 지속적 배포(CD)에 적합.
  - 브랜치 구성 예:
    - `main`과 `feature/`만 사용
  - 프로세스:
    1. `main`에서 파생된 브랜치 생성 (ex. `feature/login`)
    2. 기능 구현 후 커밋 및 푸시
    3. Pull Request 생성하여 코드 리뷰 요청
    4. 리뷰 승인 후 `main`에 Merge
    5. Merge 후 자동 배포 가능

---

### 1.2. Pull Request

- **Pull Request** : 브랜치 간 코드 변경 사항을 병합하기 전 리뷰를 요청하는 것.
  - 팀 내 코드 품질을 유지하고 기능 단위로 변경 사항을 추적할 수 있게 해준다. (코드를 그냥 바로 합치지 않고 PR을 통해 리뷰를 받으면, 문제를 미리 발견할 수 있고 코드 품질도 개선된다.)
  - PR은 단순한 병합 요청이 아니라, 함께 일하는 과정에서 중요한 소통과 검토 도구.

- **작업부터 머지까지의 프로세스**
  ```
  Fork/Clone → 브랜치 생성 → Commit → Push → PR 생성 → 리뷰/수정 → Merge
  ```

- **이상적인 PR**

  **1. 작고 명확한 단위로 나누기**
  - 큰 PR은 리뷰어에게 부담을 주고 전체 코드 오류를 찾기 어려워짐.
  - 기능 하나 또는 논리적으로 독립적인 단위로 나누기.

  **2. Self-Review후 올리기**
  - 코딩 컨벤션 위반, 불필요한 디버깅 코드 등은 PR을 받기 전에 수정 및 삭제

  **3. 의도를 설명하는 제목과 본문 작성**
  - 무엇을, 왜 수정했는지를 명확하게 서술
  - 리뷰어에게 맥락을 이해시키는 것

  **4. 리뷰어 지정 및 피드백 반영**
  - PR 생성 시 담당 리뷰어를 지정, 슬랙 등에 리뷰 요청 알리기
  - 리뷰 코멘트 확인 시 답변/이모지 남기고, 반영할 것이 있다면 반영하기

  **5. 자동화 도구와 함께 사용**
  - 코드 스타일 검사(lint), 유닛 테스트, 빌드 성공 여부 등을 GitHub Actions 같은 CI 도구로 PR 생성 시 자동 확인 가능
  - PR에 자동으로 라벨을 달거나 메시지 템플릿을 생성하는 워크플로우도 설정 가능

---
## 2. LLM(Large Language Model)

### 2.1. LLM

- **LLM(Large Language Model)** : 대규모 텍스트 데이터를 기반으로 학습하여 인간처럼 자연어를 이해하고 생성할 수 있는 모델.

- **LLM 예시** : GPT (OpenAI), Gemini (Google), Claude (Anthropic), LLaMA (Meta) 등

---

### 2.2. LLM의 동작 원리, 학습, 추론

- **LLM의 핵심 구조, Transformer** : 기존 RNN, LSTM의 한계를 극복한 구조로, 병렬 처리가 가능하고 문맥 정보 반영에 강점을 가짐.

- **Transformer 내부 구성 요소**
  - **Tokenization**: 문장을 subword 단위로 나누어 숫자 토큰으로 변환
  - **Embedding**: 토큰을 고차원 벡터로 변환 (단어의 의미를 수치화)
  - **Positional Encoding**: 순서 정보를 주입하여 단어 간 관계를 학습할 수 있도록 함
  - **Multi-head Self-Attention**: 문장 내 모든 단어의 관계를 동시에 고려, 중요 단어에 가중치 부여
  - **Feedforward Neural Network**: Attention 이후 각 위치에서 비선형 변환 수행
  - **Residual Connection + LayerNorm**: 안정적인 학습을 위한 보조 구조

- **동작 흐름**
  ```
  입력 문장 → Tokenize → Embedding + Positional Encoding → Transformer Encoder/Decoder Layer (Self-Attention + FFNN) → 출력 토큰 예측 → 디코딩 후 자연어 출력
  ```

- **학습 방식**

  **1. Pretraining (사전 학습)**  
    - 대규모 범용 텍스트 데이터(웹, 논문, 뉴스 등)로 **self-supervised learning** (많은 양을 보여주는 방식, 정답 따로 필요 없음)
    - 보통 다음 토큰 예측 또는 masked token 복원 방식

  **2. Finetuning (미세 조정)**  
    - 특정 작업(예: 요약, 번역, QA)을 잘하도록 하기 위해 labeled dataset(정답이 있는 데이터셋)으로 별도로 추가 학습
    - Task-specific 성능을 높이기 위한 단계

- **Inference(추론)** : 사용자가 질문이나 프롬프트를 입력하면, 모델이 학습된 패턴을 바탕으로 응답을 생성함. 다음에 올 단어를 확률적으로 예측하며 한 단어씩 문장을 생성해 나가는 것.

- **디코딩 전략** : 추론 시 어떤 단어를 선택할지를 결정하는 방식. 디코딩 전략들은 조합하여 사용되며, 답변의 정확성, 다양성, 창의성을 조절하는 데 중요한 역할을 함.
  - Greedy Search: 매 순간 확률이 가장 높은 단어만 선택. 빠르고 일관성 있지만, 반복이나 단조로운 문장이 나올 수 있음.
  - **Top-k** Sampling: 확률이 높은 상위 k개의 후보 중에서 무작위로 하나를 선택해 다양성을 높임. (ex. k=5)
  - **Top-p** (Nucleus) Sampling: 누적 확률이 p(예: 0.9)를 넘을 때까지의 후보만 고려하여 그 안에서 무작위로 선택.
  - **Temperature**: 확률 분포의 날카로움을 조절. 값이 낮으면 결정적(Greedy에 가까움), 높으면 더 창의적이고 다양성이 커짐.

---

### 2.3. Prompt Engineering

- **Prompt** : LLM에게 특정 작업을 시키기 위해 입력하는 문장.  
  동일한 모델이라도 prompt 작성 방식에 따라 응답 품질이 크게 달라짐.

- **Prompt Engineering의 중요성**
  - Finetuning 없이 다양한 작업을 수행 가능하게 함. 서비스 응답 품질에 직접적인 영향을 주기에, LLM을 다루기 위해 핵심 기술.

- **Prompt Engineering 기법 유형**

  - **Zero-shot prompting** : 예시 없이 직접 지시.
     - ex) `"이 문장을 영어로 번역해줘: 나는 학교에 간다"`

  - **Few-shot prompting** : 예시 몇 개와 함께 지시.
     - 입력 안에서 "이렇게 대답하라"는 힌트를 제공. finetuning 없이 모델이 동일한 방식으로 다음 질문에 답하도록 유도.

     - ex) 프롬프트 입력:
       ```
       Q: 서울은 어느 나라에 있나요?  
       A: 한국에 있습니다.  
       Q: 도쿄는 어느 나라에 있나요?  
       A: 일본에 있습니다.  
       Q: 베를린은 어느 나라에 있나요?  
       A:
       ```
       응답: `A: 독일에 있습니다.`

  - **Chain-of-Thought (CoT) prompting** : 모델이 단계적으로 사고하게 유도하여 복잡한 reasoning 문제 해결 능력 향상. 
     - 연산, 논리, 조건 추론이 필요한 문제에 특히 효과적.  
     - 작성 형태: `"답을 구하기 전에 생각하는 과정을 단계별로 써줘"`
     - ex) 프롬프트 입력:
       ```
       Q: 철수는 3개의 사과를 가지고 있고, 민수는 철수보다 2개 더 많다. 민수는 몇 개의 사과를 가지고 있나요?
       A: 생각을 단계별로 써줘.
       ```
       응답:
       ```
       A:
       - 철수는 3개의 사과를 가지고 있다.
       - 민수는 철수보다 2개 더 많으므로, 3 + 2 = 5.
       - 따라서 민수는 5개의 사과를 가지고 있다. ✅
       ```

  - **Instruction prompting** : 명시적으로 역할과 출력을 지시.
     - ex) `"너는 법률 전문가야. 아래 계약서 문장을 쉽게 설명해줘."`

- **Prompt 작성의 Best Practice**
  - **역할 부여하기**: `"너는 의사야"`, `"너는 고객센터 상담원이야"`
  - **형식 지정하기**: `"표 형식으로 정리해줘"`, `"Markdown으로 작성해줘"`
  - **출력 제약 걸기**: `"세 문장 이내로 요약해줘"`, `"한글로 대답해줘"`

- **고급 전략 (optional)**
  - **Prompt Chaining**: 여러 프롬프트를 순차적으로 연결해 중간 결과를 활용하면서 복잡한 작업을 단계적으로 수행하는 방식. 

     - ex) 기사 → 요약 → 감정 분석 (각 프롬프트의 출력을 다음 단계의 입력으로 넘김)

       [Step 1] 기사 요약 프롬프트 입력:
       ```
       Prompt 1: 아래 기사를 한 문장으로 요약해줘.
       기사: "삼성전자가 새로운 반도체 공장을 설립한다는 발표를 했다..."
       ```
       응답:
       ```
       삼성전자는 새로운 반도체 공장 설립 계획을 발표했다.
       ```

       [Step 2] 요약 결과를 다음 프롬프트에 활용:
       ```
       Prompt 2: 이 문장은 긍정적인가 부정적인가? 이유와 함께 감정 분석해줘.
       입력: 삼성전자는 새로운 반도체 공장 설립 계획을 발표했다.
       ```
       응답:
       ```
       긍정적입니다. 이는 경제 성장과 일자리 창출에 기여할 수 있기 때문입니다.
       ```
  - **Self-consistency decoding**: 하나의 질문에 대해 여러 번 reasoning을 시도하게 하고, 그 중 가장 자주 등장하거나 일관된 답을 선택하는 전략.
     - ex) 프롬프트 입력:
       ```
       Self-consistency decoding의 장점을 잘 드러내는 예를 보여줘.
       실제로 네가 스스로에게 질문을 해보고 나서 응답을 줘.
       간단명료하게 최소한의 토큰을 써서 대답해줘.
       과학적 사실이 아닌 주제로 해줘.
       ```
       응답:
       ```
       좋아, 아래는 Self-consistency decoding의 장점을 잘 드러내는 예야.
       (※ Self-consistency는 하나의 질문에 대해 여러 개의 reasoning 경로를 탐색한 뒤, 가장 많이 등장하는 결론을 선택하는 방식이야.)
       ---
       질문: 왜 사람들은 해가 질 때 기분이 차분해질까?
       ---
       여러 reasoning 경로 탐색:
       1. 낮 동안 활동이 많았고, 해가 지면 자연히 휴식을 준비해서다.
       2. 해질 녘엔 빛이 부드럽고 따뜻해져 심리적으로 안정감을 주기 때문이다.
       3. 저녁은 하루를 마무리하는 시간이라 감정도 정리되는 경향이 있다.
       4. 본능적으로 어두워지면 에너지를 아끼고 방어적으로 변하기 때문이다.
       5. 붉은 빛이 멜라토닌 분비를 촉진해 졸음을 유도하고 차분하게 만든다.
       ---
       Self-consistency decoding 결과 (가장 많이 등장한 공통 결론): “해질 무렵의 빛은 부드럽고 따뜻해서 사람을 차분하게 만든다.”
       ---
       ✅ 장점 요약:
       다양한 이유 중 일관된 결론을 골라 가장 자연스럽고 신뢰감 있는 답변을 제공함.
       특히 정답이 정해져 있지 않은 창의적/주관적 문제에서 유용함.
       ```
  - 최근에는 Prompt Engineering을 자동화하거나 최적화하기 위한 연구도 활발하게 진행 중 (ex. AutoPrompt, Prompt Tuning, In-Context Learning 등)
