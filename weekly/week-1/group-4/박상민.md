# 1. 1주차 학습

## Git 활용(GitHub Flow 중심)

Github Flow는 아주 간단한 git workflow 입니다.

- 단일 메인 브랜치 사용: main(또는 master) 브랜치만을 핵심 브랜치로 사용하며, 항상 배포 가능한 최신 상태를 유지합니다
- 새로운 기능이나 버그 수정을 위해 메인 브랜치에서 브랜치를 분기하여 작업합니다.
- 작업이 완료되면 Pull Request를 생성하여 코드 리뷰를 요청합니다.

![Image](https://github.com/user-attachments/assets/de76c988-63ef-45c7-9d47-62215fd454ef)

## 사전 학습(LLM, Gemini API 사용법) 주제 학습

### **LLM(대형 언어 모델)**

대량의 텍스트 데이터를 학습하여 자연어 처리 작업을 수행하는 모델입니다. 예를 들어, 문장 생성, 번역, 요약 등을 수행할 수 있습니다.
Ex) Gemini, ChatGPT, Claude 등

### 현대 LLM

현대 LLM의 기술적 핵심은 **트랜스포머 아키텍처**입니다. 이 구조는 입력된 텍스트의 전체 문맥을 동시에 파악할 수 있도록 **self-attention** 메커니즘을 사용합니다. 이를 통해 긴 문장이나 복잡한
문맥에서도 일관성 있고 상황에 맞는 반응을 생성할 수 있습니다.

트랜스포머는 기존 순환 신경망(RNN)이나 LSTM보다 병렬 처리가 용이해 **대규모 데이터 학습에 적합**합니다.

### LLM 과정

1. 사전 학습

- 사전 학습(Pre-training)은 대규모 언어 모델(LLM, Large Language Model) 개발의 첫 단계로, 방대한 텍스트 데이터를 통해 언어의 구조, 문법, 사실, 추론 능력 등을 모델에
  학습시키는
  과정입니다.

2. 미세 조정

- 대표적인 사전 학습 방식은 "다음 토큰 예측"으로, 주어진 문맥에서 다음에 올 단어(토큰)를 예측하도록 모델을 훈련합니다.
- 사전 학습이 끝난 모델은 "베이스 모델"이 되며, 이후 특정 업무나 도메인에 맞게 추가로 미세 조정(Fine-tuning)할 수 있습니다.

3. 추론

- 적절하게 Fine-tuning 된 모델을 이용해 inferece(추론) 과정을 통해 실제 사용자가 원하는 결과를 생성합니다.

## Gemini API 사용법

```python
from google import genai

client = genai.Client(api_key=API_KEY)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Hello world",
)

print(response.text)
```
## PR-Agent 의 model 호출 방식

PR-Agent [ai_handlers](https://github.com/qodo-ai/pr-agent/tree/baf361f0f087456397909a6d487e430c71acc5a3/pr_agent/algo/ai_handlers) directory에 있는 여러 handler 통해 여러 AI vendor의 model를 호출합니다.

base_ai_handler.py 를 구현한 langchain_ai_handler.py, litellm_ai_handler.py, openai_ai_handler.py 로 존재, 전략패턴으로 유연하게 model 변경을 가능하게 만들었습니다.

litellm 같은 경우는 모든 모델을 지원하지만, openai, langchain이 왜 존재하는지 추후 확인 예정입니다.
