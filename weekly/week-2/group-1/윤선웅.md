## 📑 목차

1. **개요 및 용어 관계도**  
2. **Retrieval-Augmented Generation (RAG)**  
   2.1 배경  
   2.2 최초 논문 (2020)  
   2.3 LLM + RAG  
   2.4 RAG 핵심 : Retrieval  
3. **AI Agent**  
   3.1 개념 및 필요성  
   3.2 RAG vs AI Agent 비교  
   3.3 AI Agent 유형·방법론  
   3.4 Agent 도입 판단 기준  
4. **Model Context Protocol (MCP)**  
   4.1 MCP 개념과 필요성
   4.2 MCP 구조  
   4.3 데이터·툴 연동 흐름  
5. **Agent-to-Agent Protocol (A2A)**  
   5.1 A2A 개념  
   5.2 A2A 아키텍처  
   5.3 MCP vs A2A 비교  
6. **참고문헌**



## **1. 개요 및 용어 관계도**

| **범주** | **핵심 목적** | **프로토콜/패턴** | **상호 의존성** |
| --- | --- | --- | --- |
| **지식 확보** | 외부 문서·DB로 LLM 환각·지식 결손 완화 | **RAG** | Retriever 성능이 AI Agent 의 ‘사고 흐름’ 신뢰도 결정 |
| **행동 주체** | 도메인 업무를 ‘자율’ 수행 | **AI Agent** | 실행 단계에서 MCP·A2A 로 도구/타 Agent 호출 |
| **도구 호출** | LLM이 API·데이터를 안전히 이용 | **MCP** | Agent 가 외부 Tool·DB 와 대화할 표준 I/F |
| **다중 Agent 협업** | Agent ↔ Agent 상호 운용성 | **A2A** | 각 Agent 가 보유한 MCP Tool·지식을 공유 |

## **2. Retrieval-Augmented Generation (RAG)**

### 2.1 배경

대규모 언어 모델(LLM)은 사전 학습 이후 지식이 없거나 특정 도메인 정보가 부족해 환각(hallucination)·노후화(out-dated) 문제가 발생한다.
RAG는 “검색(Search) + 생성(Generation)” 융합으로 이러한 한계를 재학습 없이 완화하며, LLM 실전 배치의 기본 옵션이 되었다.

### **2.2 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks(2020)**

![image](https://github.com/user-attachments/assets/3b31e9ab-8793-41e0-ae6d-c82b81463cb5)


> 이 [논문](https://arxiv.org/abs/2005.11401?ref=pangyoalto.com)에서 처음 제시한 RAG는 크게 Retriever와 Generator로 구성된다.
> 
- **Retriever:**  위키피디아와 같은 데이터셋으로부터 쿼리에 알맞은 문서(latent documents)들을 가져온다(검색한다). 이때 데이터셋은 vector index를 가지고 있어 pretrained retriever가 문서를 가져올 수 있다.
- **Generator**는 쿼리와 Retriever가 구한 문서들을 같이 받아 output을 생성한다.

| **구분** | **내용** |
| -------- | --------------------- |
| **구성** | ① **Retriever** : 위키 등에서 질의-연관 문서 *z* K개 추출<br>② **Generator** : 질의 *x* + 문서 *z* → 정답 *y* 생성 |
| **목표** | Retriever와 Generator를 **공동 Fine-Tuning**해 *parametric* 지식(모델 내부)과 *non-parametric* 지식(외부 문서)을 결합 <br>→ RAG를 모델 **Fine-tuning** 방법으로 제시 |
| **모델** | **Retriever** : DPR (BERT-Encoder)<br>**Generator** : BART |

> 초기 RAG는 “모델 성능을 높이기 위한 **학습 전략**”으로 소개되었으나, LLM 대중화 이후에는 “학습이 끝난 모델의 **추론 단계 레버리지**” 방식으로 쓰임새가 완전히 이동했다.
> 

### 2.3 LLM + RAG

![image](https://github.com/user-attachments/assets/8435bcdb-33d2-4bf9-9f05-2d227abf9da8)


[Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997?ref=pangyoalto.com)(2023)

> 최근에는 RAG를 LLM의 능력을 레버리지하는 inference에서 적용하는 경우가 늘어났다. LLM의 inference 단계에서 RAG를 적용하면 LLM의 단점인 hallucination 및 outdated knowledge를 생성을 완화할 수 있다.
> 

**RAG의 3단계**

![image](https://github.com/user-attachments/assets/c17a235a-c62d-4632-a247-eb218ef58722)


**Indexing ― “자료를 벡터 DB에 어떻게 넣어 둘까?”**

| **키 질문** | **핵심 선택지** | **조정이 미치는 지표** |
| --- | --- | --- |
| 문서를 몇 토큰 단위로 자를까? | **Chunk 크기** (예: 256‧512 tokens)<br>**Overlap** (10 – 20 %) | **Recall**<br>· Chunk가 크면 디테일 정보 파악 어려움<br>· 작으면 의미 단위가 끊겨 관계 파악 어려움 |
| 검색 후 필터링‧정렬에 쓸 정보는? | **메타데이터** (카테고리, 작성 시점, 언어, 보안 등급 …) | **Precision & Governance**<br>· “2024년 이후 문서만” 같은 필터 가능 |
| 임베딩 표현력을 높이려면? | **Embedding 모델**<br>· 범용 (E5, Ada-002) vs 도메인 특화 (LoRA 미세조정) | **Recall & Precision** 모두 영향<br>· 표현력이 좋아질수록 의미가 먼 표현도 매칭 |

 **Retrieval ― “쿼리에 딱 맞는 문맥 K개를 뽑아라”**

| **키 질문** | **핵심 선택지** | **조정이 미치는 지표** |
| --- | --- | --- |
| 유사도를 어떻게 계산할까? | **벡터 검색 알고리즘**<br>· HNSW (속도↑, RAM↑)<br>· IVF-PQ (대규모, 속도↓) | **Top-k Hit Rate / Latency** |
| 정확 키워드가 중요한 도메인인가? | **키워드 (BM25)** 병행 여부 | **정밀도 (Precision)**<br>· 고유명사·숫자 정확도 향상 |
| 두 방식을 어떻게 섞을까? | **하이브리드 퓨전** (가중합, Reciprocal Rank 등) | Precision ↔ Recall 균형 |
| 모호한 질의는 어떻게 보완할까? | **쿼리 확장** (LLM으로 동의어·관련어 추가) | **Recall**<br>· 적지 않은 표현까지 검색 |


**Generation ― “뽑아온 문맥으로 답안을 쓰는 단계”**

| **키 질문** | **핵심 선택지** | **조정이 미치는 지표** |
| --- | --- | --- |
| LLM에 어떤 형식으로 넘길까? | **Prompt 템플릿** (역할 지시, 인용 규칙, 단계적 추론 CoT) | **Hallucination 률 / 일관성** |
| 너무 많은 문맥을 어떻게 줄일까? | **Chunk 요약·압축** 또는 **핵심 문장 선택** | **Token 비용·지연** 감소 + 중간 정보 손실 방지 |
| 가져온 문맥의 순서를 바꿀까? | **재랭킹 (Reranker)**<br>· Cross-Encoder (BGE, monoT5) | **Fact F1 / Precision**<br>· 근거 문서가 앞에 오게 하여 사실성↑ |

---

**RAG의 분류**

![image](https://github.com/user-attachments/assets/03116cab-0405-4031-acb8-b34fd1d42883)


| **구분** | **핵심 목표** | **파이프라인 구조** | **장점** | **한계** |
| --- | --- | --- | --- | --- |
| **Naive RAG** | “검색 → 생성” 기본형 (빠른 PoC) | *Indexing → Retrieval → Generation* | 구현이 쉽고 빠름<br>프롬프트 엔지니어링만으로도 개선 가능 | Retrieval 누락·중복 잦음<br>긴 컨텍스트로 비용·지연↑<br>환각 완화 한계 |
| **Advanced RAG** | Retrieval·컨텍스트 품질 **고도화** | *Naive* + **Pre-Retrieval**(쿼리 확장·메타 필터) + **Post-Retrieval**(재랭킹·요약·압축) | Top-k Hit↑, 비용↓<br>Hallucination 최대 40 % 감소 | 파이프라인 복잡도↑<br>실험·튜닝 비용 증가 |
| **Modular RAG** | 단계별 **플러그인·패턴화**<br>“교체·조합 가능한 조립식” | **Pipeline Orchestrator** 가 각 모듈(Indexer, Retriever, Reranker, Compressor, LLM) 동적 호출 | 유스케이스별 최적 블록 조합<br>A/B 스왑·버전 관리 용이 | 표준·호환성 초기 단계<br>운영 레퍼런스 부족 |

### 2.4 RAG의 핵심 : Retrieval

RAG에서 통제할 수 있는 것은 Retrieval로 가져오는 문서 뿐이다. 

> 그렇기에 1)**어떻게 문서를 잘 가져올 것이며,** 2)**가져온 문서들을 쿼리와 조합**하여 LLM에 어떻게 넘길 것인지가 중요하다.
> 

(1) 문서를 잘 가져오는 방법

| **영역** | **세부 전략** | **효과** |
| --- | --- | --- |
| **Data Structure** | PDF, HTML, Knowledge Graph까지 청크 → 텍스트 병합 | 소스 다양성 확장 |
| **Granularity** | Phrase vs Sentence vs Chunk vs Doc | 노이즈·중복 최소화 |
| **Embedding** | 도메인 LoRA 미세조정· | 정밀도 ↑ |
| **Query Optimization** | LLM-기반 쿼리 확장, Typos 교정 | Recall ↑ |

(2) 문서를 쿼리와 조합하는 방법

| **영역** | **세부 전략** | **기대 효과·지표 개선** |
| --- | --- | --- |
| **Rerank** | BGE-m3, monoT5, Rule 기반 MRR | Precision ↑ |
| **Context Compress** | 중요 문장 추출, 요약 | 토큰 비용 절감 |

---

## **3. AI Agent**

![image](https://github.com/user-attachments/assets/2fe384da-4081-4985-adb9-2c75fd7e8752)


### 3.1 AI Agent 개념 및 필요성

AI Agent :  LLM을 활용하여 결정을 내리고 작업을 실행하며 목표 달성을 위해 여러 단계를 조율하는 소프트웨어 주체

AI Agent는 복잡한 의사결정이나 자율성이 요구되는 작업이나, 변화가 많은 환경에서의 자동화의 이점을 받을 수 있기에 효과적이다.

```markdown
사례 : 온라인 쇼핑 비즈니스를 운영하는 상황에서 매일 수백건의 CS(주문 상태, 제품 정보, 배송정보 등)를 받는다고 했을때 

→ AI Agent는 질문에 대하여 주문 관리 시스템에서 해당 정보를 찾고, 검색된 정보를 기반으로 고객에게 업데이트 정보를 제공하면서 관련 후속 업무를 수행할 수 있다.
```

### 3.2 RAG vs AI Agent

RAG는 LLM을 도와서 주어진 문맥을 기반으로 정확한 답변을 제공하려고 합니다.
그러나 AI Agent는 그 답변을 받아서 결정을 내리고, 작업을 실행하며, 목표 달성을 위해 여러단계를 조율하기도 합니다.

그렇다면 RAG와 AI Agent의 차이는?

| 구분 | **RAG** | **AI Agent** |
| --- | --- | --- |
| **정의** | 외부 DB 등 **소스 데이터를 검색**해 LLM 응답을 강화 | LLM을 사용해 **의사 결정을 내리고 작업을 실행**하며 다단계 프로세스를 조율 |
| **역할** | • 사용자 입력 시 **적절한 문서** 검색 → **정확한 답변** 생성<br>• **최신 정보** 반영, 문서 검색‧요약 | • 검색 정보로 **행동** 수행 및 여러 작업 연계<br>• **자동화된 작업**·의사 결정 지원<br>• **상호작용 기반** 문제 해결 |
| **작동 방식** | 1) 질문 분석 → 2) DB 검색 → 3) 검색 문맥과 함께 **LLM 답변** | 1) 입력 분석·정보 수집 → 2) **계획 수립** → 3) **액션 수행/상호작용** → 4) 결과 조율·응답 |
| **주요 사례** | • 법률‧정책 Q&A<br>• 기술 문서 검색 응답<br>• **내부 DB** 고객 지원 | • 챗봇 대화 후 **예약 자동 진행**<br>• AI **워크플로 자동화** |
| **장점** | • 최신 정보 반영<br>• 문맥 일관성 강화 | • 다양한 환경 적용, **지속 학습**<br>• **반복 작업 자동화** |
| **한계** | • 문서 품질 의존<br>• 검색·생성 최적화가 분리 | • 복잡 결정 과정 오류 가능<br>• **신뢰성·보안** 이슈 |

---

### 3.3 AI Agent의 종류와 방법론

RAG에도 Naive, Advanced, Modular 방식이 있고, 검색에서도 Pre-retrieval, Post-Retrieval, Re-ranking등 다양한 방법이 있는 것처럼 AI Agent도 다양한 방법과 그 특징이 존재한다.

| 종류 | 주요 특징 | 사용 예시 |
| --- | --- | --- |
| **Fixed Automation Agent** | • 추론 없이 동작 범위 고정<br>• 패턴화된 행동만 실행 | RPA, 단순 스크립트 |
| **LLM-Enhanced: Smarter, but not Einstein** | • 컨텍스트 기반 LLM 응답<br>• Rule 제한·State 관리 없음 | 이메일 필터링, 콘텐츠 모더레이션 |
| **ReAct: Reasoning Meets Action** | • 다단계 워크플로·동적 계획 가능<br>• 기본 문제 해결 | 여행 일정 플래너, 프로젝트 계획 |
| **ReAct + RAG: Grounded Intelligence** | • 외부 지식 접근 → 환각 감소<br>• 실시간 데이터 활용 | 법률 리서치, 의료 어시스턴트 |
| **Tool-Enhanced: The Multi-Taskers** | • 다수 툴 호출·동적 실행<br>• 고수준 자동화 | 코드 생성 Copilot, 데이터 분석 봇 |
| **Self-Reflecting: The Philosophers** | • 메타 인지·설명 가능성<br>• 자기 개선 루프 | QA Agent |
| **Memory-Enhanced: The Personalized Powerhouses** | • 장기 메모리·개인화·적응형 학습 | AI 개인 비서 |

### 3.4 AI Agent를 사용해야할 경우

| **Agent가 필요한 경우** | **Agent가 불필요한 경우** |
| --- | --- |
| • **복잡한 의사결정·자율성·적응성**이 요구되는 다단계 업무<br>• **동적(Dynamic) 프로세스** — 단계가 많고 상호작용이 잦은 흐름<br>• **실시간 고객 지원·헬프데스크**처럼 즉답·연속 대응이 필요한 서비스<br>• **데이터 수집·처리·분석·조사**를 주기적으로 수행해야 하는 업무<br>• **개인화 교육·훈련** 등 지속적 피드백·맞춤형 경험이 필요한 환경 | • **단순·저빈도 작업** — 기존 매크로·스크립트로도 충분히 자동화 가능<br>• **심층 전문 지식**이 필수인 고난도 법률·의료 진단 등은 **인간 전문가**가 바람직<br>• **감성·창의성·심리 상담** 등 인간적 요소가 핵심 가치인 업무 |

**[참고] AI Agent 도입을 고려하기 위한 10개의 질문**

| **질문** | **고려 내용** |
| --- | --- |
| 1. 작업의 복잡도 | 단순 반복인가, 복잡한 의사결정이 포함돼 있는가? |
| 2. 작업의 발생 빈도 | 빈번하게 발생해 자동화로 시간·비용 절감 효과가 큰가? |
| 3. 데이터 처리·요청량 | 대량 데이터·고속 처리가 필요한가? |
| 4. 변화 적응성(Adaptability) | 업무 조건이 자주 변하며 즉각적 대응이 요구되는가? |
| 5. 학습·진화 가능성 | 시간이 지남에 따라 학습·성과 향상이 기대되는가? |
| 6. 정확성 중요도 | 의료·금융처럼 높은 정확성이 필수인가? |
| 7. 인간 전문성·감성이 필요한가? | 인간의 직관·공감이 핵심 가치인가? |
| 8. 개인정보·보안 요건 | 민감 데이터 처리, 강력한 보안이 필요한가? |
| 9. 규제·법적 요구 | 산업 규제·컴플라이언스 제약이 존재하는가? |
| 10. 비용 대비 효과(ROI) | Agent 구축·운영 비용 대비 효율·성과가 충분한가? |

---

## **4. Model Context Protocol (MCP)**

![image](https://github.com/user-attachments/assets/9275fddb-2dd5-4f1d-91e4-d5d522642c28)


### 4.1 MCP 개념과 필요성

MCP: **2024년 11월 ‘앤트로픽’이 발표한** AI에 다양한 프로그램을 쉽게 연결해서 쓸 수 있도록 만든 표준 통신 형식

> “이 업계는 지금까지 모델 역량에 막대한 투자를 하여 추론과 품질에서 빠른 진전을 이뤘습니다. 하지만 여전히 가장 정교한 모델조차도 데이터로부터 분리되어 제약을 받고 있으며, 정보 사일로와 레거시 시스템에 갇혀 있습니다.” ([참고](https://www.anthropic.com/news/model-context-protocol))
> 

MCP는 이러한 문제를 해결하기 위해 고안되었고, AI 시스템을 데이터 소스와 연결하기 위한 보편적이고 개방적인 표준을 제공하여 **단편화된 통합을 단일 프로토콜로 대체**합니다. 

→ 결과적으로 AI 시스템은 더 간단하고 안정적인 방식으로 필요한 데이터에 접근할 수 있게 해준다.

### **4.2 MCP의 구조**

![image](https://github.com/user-attachments/assets/1916fcbe-d3ed-4f6b-88a6-e5cf25aac999)


**호스트가 여러개의 서버에 연결해서 작업을 할수 있다**는 것이 MCP 구조의 핵심이다.

| **역할** | **설명** |
| --- | --- |
| **Host** | MCP를 통해 데이터에 접근하려는 주체 (Slack·VS Code 등 Agent 실행 환경) |
| **Client** | Host 안에서 서버와 1:1 연결을 유지, Agent 호출 발신 |
| **Server** | 클라이언트의 요청을 받아 정보를 제공하거나 동작을 실행(구글 드라이브, 슬랙 등) Tool/API/DB·Prompt 등록, JSON schema 명세 제공 |


> Claude와 Notion MCP 서버를 연결하면 ‘노션에 코멘트 생성하기(notion_create_comment)’, ‘노션에 데이터베이스 만들기(notion_create_database)’ 등의 도구들이 존재 
→ 해당 도구들을 활용하여 MCP로 노션-클로드에 연결하여 다양한 프로그램 제작 가능
> 


![image](https://github.com/user-attachments/assets/c5cc3dfb-ff23-4a43-ac7a-b2b34e2c8990)

![image](https://github.com/user-attachments/assets/a683f523-e7d6-4477-a977-f55fe4b880cb)

![image](https://github.com/user-attachments/assets/56ca9991-b5a2-4715-a651-77105c4c3447)


### **4.3 데이터·툴 연동 흐름**

1. Agent → **MCP Discovery** → 사용 가능한 tool 목록 수신
2. Agent → **JSON call** → 서버측 tool 실행
3. 서버 → 실행 결과 ↩︎ Agent
4. Agent → reasoning loop 재진입

---

## **5. Agent-to-Agent Protocol (A2A)**

![image](https://github.com/user-attachments/assets/c002a3cb-90da-4f0e-a4f8-dd63cee96493)


### **5.1 A2A 개념**

Google이 2025년 4 월 발표한 **Agent2Agent(A2A) 프로토콜**은 서로 다른 회사나 프레임워크의 에이전트들이 **서로를 찾고(발견) → 조건을 맞추고(협상) → 메시지를 주고받는(대화)** 방식을 표준화한 공개 프로토콜

### **5.2 A2A 아키텍처**

![image](https://github.com/user-attachments/assets/ba5b26fa-35c9-4108-8ba0-d92d3a7e005b)


**구성 요소**

| 구성요소 | 역할 |
| --- | --- |
| **Agent 목록(Directory)** | 등록된 에이전트들의 **명함(AgentCard)** 를 보관·검색 |
| **클라이언트** | “어떤 에이전트에게 일을 맡길까?” 고르고, **작업(Task)을 전송** |
| **서버-측 에이전트** | 실제로 일을 처리하고 **진행 상황·결과** 알림 |
| **결과 보관소(Artifact Store)** | 완료된 **파일·데이터**를 저장 |

**전체 흐름**

| 단계 | 클라이언트가 하는 일 | 에이전트/서버가 하는 일 |
| --- | --- | --- |
| ① **에이전트 찾기** | “검색” 버튼 → 조건에 맞는 **AgentCard** 목록 받기 | — |
| ② **작업 맡기기** | 원하는 AgentID에 **Task 요청** 전송 | Task ID를 만들어 작업 시작 |
| ③ **진행 상황 듣기** | SSE 스트림 구독 *혹은* Webhook 기다리기 | “진행 중…”, “50 % 완료” 등 상태 이벤트 발송 |
| ④ **추가 정보 필요** | — | “input-required” 상태 알림 |
| ⑤ **추가 정보 보내기** | 부족한 정보 메시지 추가 전송 | 정보 반영 후 작업 계속 |
| ⑥ **작업 종료** | — | “완료” or “실패” 상태 + **Artifact ID** 전달 |
| ⑦ **결과 받기** | Artifact ID로 **파일/데이터 다운로드** | — |

### **5.3 MCP vs A2A**

- **MCP** : Agent↔Tool(외부 시스템) 통신
- **A2A** : Agent↔Agent 통신

> 두 프로토콜이 **경쟁**이라기보다 상보적 계층으로 자리잡고 있다는 평가가 다수
> 

---

## 6. 참고문헌

https://arxiv.org/abs/2005.11401

https://arxiv.org/abs/2312.10997

https://www.galileo.ai/ebook-mastering-agents

https://www.anthropic.com/news/model-context-protocol

[https://medium.com/rate-labs/rag의-짧은-역사-훑어보기-첫-논문부터-최근-동향까지-53c07b9b3bee](https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee)

https://lsjsj92.tistory.com/682

https://google.github.io/A2A/?utm_source=pytorchkr

https://discuss.pytorch.kr/t/google-ai-a2a-agent-to-agent/6761
