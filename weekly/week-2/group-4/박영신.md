## RAG 정리

**🔗 참고 자료**

- NVIDIA 블로그: ["What is Retrieval-Augmented Generation?"](https://blogs.nvidia.com/)
- StackOverflow 블로그: ["Practical Tips for Retrieval-Augmented Generation"](https://stackoverflow.blog/)
- AWS 블로그: ["RAG란 무엇인가"](https://aws.amazon.com/ko/blogs/)
- REALM 논문: [REALM: Retrieval-Augmented Language Model Pre-Training (Guu et al., 2020)](https://arxiv.org/abs/2002.08909)

### **1. RAG란 무엇인가?**

**Retrieval-Augmented Generation (RAG)** 은 **외부 지식 검색** + **텍스트 생성**을 결합한 방법으로, LLM이 **자신의 파라미터에 저장된 지식**만 사용하는 대신, **외부 데이터 소스(문서, DB, 위키 등)** 에서 **관련 정보를 검색**해 그 정보를 **컨텍스트로 활용**하여 답변을 생성하는 것이다.

**비유**

기존 LLM이 "닫힌 책 시험"을 본다면, RAG를 쓴 LLM은 "열린 책 시험"을 본다.

> "질문 → 검색 → 답변 생성" 흐름을 자동화하는 시스템
> 

---

### 2.  RAG가 필요한 이유

| **문제** | **설명** | **RAG가 해결하는 방법** |
| --- | --- | --- |
| 모델 지식 최신성 부족 | 학습 이후 생긴 정보는 알지 못함 | 질문 시점에 실시간 검색 |
| 환각(Hallucination) 문제 | 그럴듯하지만 틀린 답변을 생성 | 외부 근거를 근거로 답변 생성 |
| 재학습 비용 | 새로운 지식을 반영하려면 모델 전체 파인튜닝 필요 | 지식베이스만 업데이트 |
| 대형 모델 부담 | 모든 지식을 모델에 넣으려면 초거대 모델 필요 | 소형 모델 + 외부 지식 연결 |
| 답변 투명성 부족 | 어디서 정보를 가져왔는지 알 수 없음 | 출처와 함께 답변 가능 |

---

### 3. RAG의 작동 원리

1. **지식베이스 구축**
    - 문서를 작은 청크(chunk)로 분할
    - 각 청크를 임베딩(벡터화)
    - 벡터 데이터베이스(Vector DB)에 저장
2. **질문 임베딩 및 검색**
    - 사용자의 질문을 벡터로 변환
    - Vector DB에서 **가장 유사한 문서 청크**들을 검색
3. **프롬프트 보강**
    - 검색된 문서들을 **컨텍스트로 추가**하여 LLM에 입력
4. **LLM 답변 생성**
    - 질문 + 검색된 정보 기반으로 답변 생성
    - 필요 시 출처(citation) 포함

---

### 4. RAG 아키텍처 구성 요소

| **컴포넌트** | **역할** |
| --- | --- |
| **임베딩 모델** | 텍스트를 고차원 벡터로 변환 (문서/질문 둘 다) |
| **벡터 데이터베이스 (Vector DB)** | 임베딩된 문서 청크를 저장하고, 유사 검색 |
| **검색기 (Retriever)** | 질문 임베딩을 기반으로 관련 문서 검색 |
| **생성 모델 (Generator, LLM)** | 질문 + 검색 문서를 바탕으로 최종 답변 생성 |

**기술 예시**

- 벡터 DB: Faiss, Pinecone, Weaviate, Qdrant
- 임베딩 모델: OpenAI ada-002, Sentence-BERT, Cohere
- 생성 모델: GPT-3.5, GPT-4, Llama 2

---

### 5. RAG의 장점

**[1] 사실성 향상 및 환각 감소**

- 기존 LLM은 모르는 것도 그럴듯하게 답변하는 "환각"이 많음
    
    → LLM은 훈련할 때 배운 정보만 기억하고, 그 이후 생긴 건 모르는 상태로 그냥 추측해야 하기 때문
    
- **RAG**는 질문할 때 **외부에서 관련 자료를 찾아**와서 답변하기 때문에, 추측하는 대신, **근거를 기반으로 정확한 답변 가능**

**[2] 지식 최신성 보장**

- LLM은 학습한 시점 이후의 사건(예: 2024년 뉴스) 같은 걸 기본적으로 모르지만, RAG를 사용하면, 질문 시점에 바로 **최신 문서**를 검색해서 **새로운 정보**를 답변에 반영 가능

**[3] 모델 경량화**

- 원래는 지식이 많을수록 **모델 크기(파라미터 수)** 를 키워야 했음 → 거대 LLM
- 하지만 RAG를 쓰면, 모델 자체는 가볍게 유지하고 필요할 때 외부 지식베이스를 조회하면 되기에 모델이 가벼워짐

**[4] 도메인 특화 적응**

- LLM이 기본적으로는 범용 지식만 가지고 있으나 RAG는 특정 산업(예: 의료, 법률, 금융), 특정 회사(예: 삼성전자 내부 규정) 등 이런 전문적/내부적 지식까지 붙여주는 것이 가능함

---

### 6. RAG의 한계와 주의점

| **문제점** | **설명** |
| --- | --- |
| 검색 실패 위험 | 잘못된 문서를 검색하면 틀린 답변 생성 가능 |
| 컨텍스트 길이 한계 | LLM 프롬프트 길이에 제한 (수천 토큰) |
| 구축 복잡성 | 벡터 DB, 검색 파이프라인 등 추가 필요 |
| 데이터 품질 중요 | 쓰레기 데이터 → 쓰레기 답변 |
| 보안 이슈 | 민감 정보 벡터화/검색 과정에서 유출 위험 |
| 프롬프트 설계 필요 | 컨텍스트를 효과적으로 활용하도록 최적화해야 함 |

<br>
<br>

---

## MCP 정리

**🔗 참고 자료**

- [YouTube 영상: MCP에 대한 짧은 설명 (2024)](https://www.youtube.com/watch?v=KZwV6dOfNuE)
- [Pytorch Discuss: MCP에 대한 글 정리](https://discuss.pytorch.kr/t/deep-research-model-context-protocol-mcp/6594/1)
- [Velog: What is MCP?](https://velog.io/@k-svelte-master/what-is-mcp?utm_source=oneoneone)

### 1. MCP란 무엇인가?(Model Context Protocol)

MCP는 LLM이 외부 리소스(문서, 데이터), 도구(API), 프롬프트 등과 상호작용할 수 있도록 설계된 표준 프로토콜이다.

기존에는 LLM과 외부 시스템을 연결할 때마다 별도 API 통합이 필요했지만, MCP는 이를 표준화해 간단하고 유연한 통합을 가능하게 하며, Anthropic에서 주도하여 만든 오픈소스 규격이다.
이는 요즘 LLM을 기반으로 한 에이전트 시스템을 실현하는 핵심 인프라로 주목받고 있다.

우선 간단하게 먼저 보면,
MCP를 통해:
	•	LLM은 정해진 구조의 “Context”를 받아보고,
	•	외부 Tool을 호출하거나 Resource를 참조해 응답을 생성할 수 있는 것이다.

---

### 2. 작동 구성 요소 (아키텍처)

MCP 시스템은 아래 세 가지 주요 컴포넌트로 구성된다.
| **구성 요소** | **역할** |
| --- | --- |
| Host | LLM을 실행하는 인터페이스(ex. IDE, Chat UI, Assistant 플랫폼 등) |
| Client | Host 내부에서 동작, MCP 서버와 통신 |
| Server | 외부 도구, 데이터, 문서 등을 실제로 제공 |

*MCP는 JSON-RPC 2.0을 기반으로 작동한다.

---

### 3. MCP Context 구조

MCP 서버는 모델이 활용할 세 가지 Context 요소를 제공한다. 이는 다음과 같다.
| **요소** | **설명** |
| --- | --- |
| resources | 읽기 전용 문서, 텍스트, 코드 등 모델이 참고할 정보 |
| tools | 호출 가능한 함수/도구(ex. 날씨 API, 코드 분석기 등) |
| prompts | 모델의 행동을 유도하는 지침이나 템플릿 |

---

### 4. MCP 시스템의 흐름 (실제 동작 방식)
① 탐색 (Discovery)
- MCP 클라이언트는 MCP 서버의 '.well-known/agent.json' 파일을 읽어
- 해당 서버가 제공하는 tools, resources, prompts 목록을 파악한다.

② 작업 위임 (Delegation)
	•	적절한 MCP 서버를 선택하고,
	•	작업(task)을 JSON-RPC 형태로 전달하여 처리 요청한다.

③ 스트리밍 업데이트 (Streaming Updates)
	•	서버는 작업 진행 상황을 중간중간 실시간으로 전송할 수 있다.
	•	ex. 생성 중인 코드, 처리 로그, 진행률 등

④ 아티팩트 수집 (Artifact Collection)
	•	작업이 완료되면 서버는 **최종 결과물(아티팩트)**을 제공한다.
	•	클라이언트가 이를 수집하여 사용자에게 전달한다.

⑤ 완료 알림 (Completion Notification)
	•	클라이언트는 사용자 또는 상위 시스템에 작업 완료 및 결과 전달을 알린다.

---

### 5. 장단점 요약
장점
- 다양한 context를 활용할 수 있음
- 하나씩 찾아서 하거나 코드를 길게 작성하지 않아도, 파일 설정만으로 연결하여 처리할 수 있음

단점
- 모델이 context를 잘 활용하려면 세심한 설계가 필요함

<br>
<br>

---

## ACA 정리

**🔗 참고 자료**
- [A2A Github](https://github.com/google/A2A)
- [A2A protocol](https://google.github.io/A2A/#/)
- [A2A vs MCP: 새로운 에이전트 생태계를 위한 두 개의 보완적 프로토콜](https://blog.logto.io/ko/a2a-mcp)

### 1. A2A란?

다양한 AI 에이전트들이 서로 메시지를 주고받고, 작업을 나누며, 목표를 함께 달성할 수 있게 해주는 표준화된 통신 프로토콜이다.

	•	구글(Google)이 주도하는 오픈 프로토콜이며,
	•	LLM 기반 에이전트 간 연동이 어렵다는 실무의 문제점을 해결하기 위해 만들어졌다.
	•	사람과 모델 간의 대화가 아닌, 모델끼리 협업하는 시대의 기반 기술이다.

---

### 2. A2A의 핵심 개념

| **개념** | **설명** |
| --- | --- |
| 에이전트(Agent) | 독립적인 목표와 행동 로직을 가진 지능 단위 |
| Agent Card | 에이전트가 할 수 있는 일, 요구 조건 등을 명시한 JSON 문서 |
| 작업(Task) | 특정 목표를 수행하기 위해 한 에이전트가 다른 에이전트에게 보내는 요청 |
| Task ID | 작업 단위를 추적하고, 관련된 메시지를 연동하는 데 사용하는 식별자 |

---

### 3. A2A 작동 방식 (Workflow)

A2A는 클라이언트-서버 구조로 작동하며 다음 순서를 따른다.

① 에이전트 발견 (Discovery)
	•	클라이언트 에이전트가 /.well-known/agent.json에 게시된 Agent Card를 읽고,
	•	상대 에이전트가 무엇을 할 수 있는지 파악한다.
	
② 작업(Task) 생성 및 전송
	•	적절한 원격 에이전트를 찾은 뒤, JSON 형식의 Task 객체를 전송해 요청한다.
	•	전송 엔드포인트: /tasks/send, /tasks/sendSubscribe

③ 실시간 스트리밍 (SSE)
	•	서버는 **Server-Sent Events (SSE)**를 통해 작업의 상태, 진행률, 결과를 스트리밍 방식으로 전달한다.

④ 양방향 상호작용
	•	클라이언트는 같은 Task ID를 사용하여 대화를 이어가며 필요한 정보를 주고받을 수 있다.

⑤ 아티팩트 수집
	•	결과물(문서, 인증서, 요약 등)을 수집하고 활용한다.

⑥ 완료 알림
	•	작업이 완료되면 상태(성공/실패/취소)가 등록되고, 필요 시 웹훅으로도 알림을 받을 수 있다.

⸻

### 4. MCP와 A2A 비교
| **항목** | **MCP** | **A2A** |
| --- | --- | --- |
| 초점 | LLM + 외부 도구 간 통합 | 에이전트 대 에이전트 간 통신 |
| 구조 | 단일 모델 중심 | 다중 에이전트 중심 |
| 상호작용 | 컨텍스트 기반 | 작업(Task) 기반 |
| 스트리밍 | 가능 | 가능(SSE+webhook) |
| 사용 예시 | LLM에 문서나 API 전달 | 복잡한 멀티에이전트 온보딩 시스템 |

### 5. 실제 사례 – OnboardingPro

여러 부서의 에이전트들이 협업하여 신입사원을 자동으로 온보딩시키는 구조

| **에이전트** | **역할** |
| --- | --- |
| hr-agent | 직원 정보 등록, 계약서 전송 |
| it-agent | 이메일 생성, 노트북 주문 |
| facilities-agent | 책상 할당, 출입증 발급 |

	•	각 에이전트의 기능을 .well-known/agent.json을 통해 파악
	•	Task를 병렬로 전송하고, 스트리밍 방식으로 진행 상황 수신
	•	완료 시 HR 담당자에게 통합 결과 알림 전송