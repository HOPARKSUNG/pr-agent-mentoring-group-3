# 현대 AI 통신 프로토콜 개요

## RAG

**검색 증강 생성(Retrieval-Augmented Generation)**은 LLM이 자체 지식 기반 외에도 외부 데이터베이스나 검색 엔진을 활용하여 더 정확하고 최신의 정보를 제공하는 방법입니다.

### 1. 개념 및 필요성

- **지식 한계 극복**: LLM은 학습 시점 이후의 정보나 특정 도메인 지식이 부족할 수 있습니다.
- **정확성 향상**: 외부 데이터를 참고하여 사실 기반의 응답을 제공합니다.
- **업데이트 가능성**: 실시간으로 변화하는 정보를 반영할 수 있습니다.

### 2. 구성 요소

- **질의 생성(Query Generation)**: 사용자 입력을 기반으로 검색에 적합한 질의를 생성합니다.
- **정보 검색(Retrieval)**: 생성된 질의를 사용하여 데이터베이스나 인터넷에서 관련 정보를 검색합니다.
- **응답 생성(Answer Generation)**: 검색된 정보를 컨텍스트로 사용하여 최종 응답을 생성합니다.

### 3. 장점

- **사실 검증**: 생성된 응답의 정확성을 높입니다.
- **범용성**: 다양한 주제와 도메인에 적용할 수 있습니다.
- **효율성**: 필요한 정보만 검색하여 처리하므로 연산 자원을 절약합니다.

---

## MCP(Model Context Protocol)

AI에 다양한 프로그램을 쉽게 연결해서 쓸 수 있도록 만든 표준 통신 형식입니다. Anthropic 주도로 개발되고 오픈소스로 공개된 AI계의 USB-C 포트와 같은 프로토콜입니다.

### 탄생 배경

#### 문제점

- AI 품질이 빠르게 발전하고 있지만 정작 데이터에 연결되지 못해서 확장성에 한계가 존재했습니다.
- LLM과 외부 도구를 연결하는 방법은 이전에도 있었지만, 각 서비스마다 API 구조가 다르고 인증 방식이 달라 통합하는 과정이 복잡했습니다.

MCP 덕분에 규격화된 프로토콜을 통해 누구나 동일한 방식으로 API를 구현하고 연결할 수 있게 되었습니다.

#### 비유

USB의 C포트와 비유할 수 있습니다. 다양한 하드웨어 연결 포트 규격들이 USB-C로 통일되고 나서 어떤 기기들끼리도 호환이 가능해진 것처럼, MCP도 AI와 다양한 데이터 소스 및 도구를 연결하는 표준화된 방식입니다.

MCP를 활용하면 LLM 애플리케이션에 외부 앱을 연동하고 확장하는 일이 보다 쉬워져 AI 활용의 장벽이 대폭 낮아질 수 있습니다.

#### 인기도 상승

Anthropic이 처음 내놓았을 때는 인기가 없었으나, Cursor와 OpenAI에서 MCP를 지원하며 흐름이 살아났습니다.

### MCP 구성요소

- **호스트**

  - AI 모델을 운용하는 주체 애플리케이션입니다.
  - 사용자로부터 질문이나 명령을 받아 모델에게 전달하고, 모델의 응답을 사용자에게 보여주는 전체 흐름을 조율합니다.
  - MCP 클라이언트를 구동하여 MCP 서버들과 연결을 유지합니다.
  - 예시: Claude Desktop, IDE의 AI 어시스턴트(Copilot, Continue)

- **클라이언트**

  - 호스트 애플리케이션 내부에서 동작하며 하나의 MCP 서버와 1:1 연결을 담당하는 컴포넌트입니다.

- **서버**
  - 외부 데이터나 기능을 제공하는 측입니다.
  - MCP 서버는 하나의 특정 서비스나 데이터 소스를 감싸서 모델이 이해할 수 있는 형태로 맥락(Context)을 제공합니다.
  - 예: 파일 시스템 MCP 서버는 파일 읽기 기능을, 날씨 MCP 서버는 날씨 정보 제공 기능을, 데이터베이스 MCP 서버는 쿼리 실행 기능을 노출할 수 있습니다.
  - MCP 서버는 자신이 제공하는 기능을 표준화된 인터페이스로 정의하여 MCP 클라이언트 요청에 응답합니다.
  - 하나의 호스트(예: AI IDE)는 여러 MCP 서버(파일, Git, 데이터베이스 등)에 동시에 연결해 다양한 맥락을 얻을 수 있습니다.

### MCP 동작 흐름

1. 연결 및 기능 교환
2. 모델 질의 처리
3. 필요한 경우 MCP 서버 호출
4. 결과를 모델에 제공
5. 모델이 최종 응답 생산의

---

## Agent2Agent(A2A)

지금까지의 에이전트 시스템은 각자 독립적으로 동작하는 경우가 많았습니다. 프레임워크도 다르고, 개발한 벤더도 제각각이기 때문에 서로 간의 소통이 쉽지 않았습니다.

Google의 A2A(Agent-to-Agent) 프로토콜은 바로 이 문제를 해결합니다. 다양한 환경에서 만들어진 자율 에이전트들이 서로 그리고 사용자와 자연스럽게 협업할 수 있도록 표준화된 통신 방식을 제시합니다.

이제는 하나의 언어로, 더 똑똑하게 함께 일할 수 있는 기반이 마련되었습니다.

### MCP와의 차이점

| 특징          | A2A                                                          | MCP                                                                |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------------ |
| **목표**      | 독립적인 AI 에이전트 간의 원활한 통신 및 협업                | AI 모델과 외부 도구/데이터 소스 간의 안전하고 효율적인 연결        |
| **통합 대상** | 서로 다른 AI 에이전트                                        | 단일 AI 에이전트 (LLM 기반 앱)와 외부 환경                         |
| **통합 방식** | 수평적 (Agent 간의 상호 작용)                                | 수직적 (Agent와 외부 자원 간의 연결)                               |
| **주요기능**  | 에이전트 검색, 작업 위임, 결과 교환, 표준화된 통신 방식 제공 | 맥락 정보 제공 표준화, 도구 활용 인터페이스 표준화, 보안 고려 사항 |
| **비유**      | AI 전문가 그룹 간의 회의 및 협업 규칙                        | AI 비서가 필요한 정보를 얻거나 도구를 사용하는 표준화된 방법       |

### A2A 구성 요소

- **AgentCard**: 에이전트의 프로필과 기능을 정의
- **Task**: 에이전트에게 할당되는 작업 단위
- **Artifact**: 작업의 결과물

### 작동 방식

1. 클라이언트가 AgentCard를 통해 적절한 에이전트를 탐색
2. 클라이언트가 tasks/send 또는 sendSubscribe로 작업 요청
3. 서버는 작업을 수행하며 SSE(Server Sent Event) 또는 Webhook을 통해 상태 전달
4. input-required 상태일 경우 클라이언트가 메시지 추가 전송
5. 작업이 완료되거나 실패하면 최종 결과물을 Artifact로 반환
