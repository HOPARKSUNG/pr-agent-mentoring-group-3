# 개인 과제 - RAG / MCP / A2A

## RAG(Retrieval-Augmented Generation)

### 개념

LLM의 한계를 보완하기 위해 외부 지식을 결합하는 개념이다.
일반적인 LLM은 학습되어 내재되어있는 지식으로만 답변하다보니,
학습 이후에 등장한 최신 정보 반영이 어렵고, 환각현상을 보이기 쉽다.
RAG는 이를 해결하고자 모델 외부에 신뢰할 수 있는 정보 소스를 두고,
질문에 맞는 관련 정보를 검색하여 응답 생성 시 참조하게 한다.
기본 구조는 질의에 대해 벡터 DB 등에서 관련 문서를 검색하고,
LLM 프롬프트에 이 문서를 추가해 답변 생성하는 형태로 이루어진다.

### 장점

응답의 사실성 향상과 최신성을 확보 할 수 있다.
모델이 최신의 신뢰할만한 사실에 접근하므로 업데이트되는 지식도 반영할 수 있다.
또한 출처도 제시할 수 있기 때문에 사용자 입장에서는 투명성과 신뢰도가 올라간다.
LLM의 환각을 줄이고, 파인튜닝 없이도 새로운 지식을 반영할 수 있어 운용비용을 줄일 수 있다.

### 단점

RAG는 정보 검색 단계의 성능에 의존하기 때문에 잘못된 문서를 가져오면 LLM도 잘못 대답할 수 있다.
유사도 검색은 편리하지만 자연어의 의미를 잘못 파악하여 비슷하지만 의도와는 다른 결과를 내줄 가능성이 있다.
RAG를 도입하면 기존 시스템보다 복잡해진다.
임베딩이나 검색 등 다양한 단계가 생기면서 확장성과 유지보수에 더욱 신경을 써야한다.
기존의 LLM보다 근본적으로 시간이 더 걸리게 된다.
임베딩을 할 때 청크 사이즈에 대한 고려가 이루어지는데 이것은 LLM이 맥락을 이해하는데에 있어 문제가 있다.
청크를 작게하면 맥락 이해가 힘들고, 청크를 크게하면 노이즈나 저장비용이 증가한다.

### RAG 아키텍쳐

#### 지식베이스를 구축하는 단계

1. 원천 데이터를 수집한다.
2. 문서를 전처리하고 청크 단위를 설정하여 분할한다.
3. 텍스트 임베딩을 통해 정보들을 벡터로 변환한다.
4. 벡터 DB에 저장한다.

#### 질의응답이 이루어지는 단계

1. 사용자의 질문(자연어)을 임베딩한다.
2. 벡터 DB에서 유사 내용을 검색한다. (코사인 유사도 계산, kNN 알고리즘)
3. 찾은 문서를 LLM 프롬프트에 포함시킨다.
4. LLM이 해당 내용으로 최종 답변을 생성한다.

## MCP

## A2A
